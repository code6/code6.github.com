<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[MayCoder]]></title>
  <link href="http://code6.github.com/atom.xml" rel="self"/>
  <link href="http://code6.github.com/"/>
  <updated>2015-01-04T21:44:23+01:00</updated>
  <id>http://code6.github.com/</id>
  <author>
    <name><![CDATA[Code6]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[北美求职准备]]></title>
    <link href="http://code6.github.com/blog/2015/01/04/tips-for-silicon-valley-job-hunting/"/>
    <updated>2015-01-04T20:32:00+01:00</updated>
    <id>http://code6.github.com/blog/2015/01/04/tips-for-silicon-valley-job-hunting</id>
    <content type="html"><![CDATA[<p>近期离开了毕业后第一家公司，去 google zurich 工作了，还没来得及总结。有朋友想了解北美求职相关的事情，故写一点小心得仅供参考。 这里主要从在职人士的角度出发，也主要把我看过的资料，用过的服务提供给大家参考。最后附了一些资源，写的都很棒，看过一遍就会对整个北美求职有点感觉了。</p>
<h3>基本信息</h3>
<p>首先一般来说北美公司的面试时间窗口一般在下半年，从7，8月份开始一直可以延续到次年的二月份，大部分人会选择在这中间，比如九十月份来投简历面试。<br />
在这之前要准备什么呢？</p>
<ul>
	<li>一份英文简历</li>
	<li>英语听说能力</li>
	<li>专业技能</li>
</ul>
<p>一般来说大部分人不管准备了多久都会觉得没有准备好，不过到时间了还是得申请面试的。面试最好找朋友内推，网申得到面试机会的概率略小。 内推完一般来说一两个星期就可以安排面试了，走各自的面试流程即可。</p>
<h3>简历</h3>
<p>简历本该养成定期更新的良好习惯，这样就不用纠结了，可以参考我的 <a href="http://code6.github.io/blog/2013/04/15/keep-updating-your-cv/">持续更新简历</a> 。</p>
<h3>英语</h3>
<p>英语方面要求并不算高，一般做到能基本听懂，并能做出简单交流即可。面试一般都是专业词汇，稍微看点英文技术视频就会有点感觉了。更多的时候不会挂在英语上， 而是挂在专业知识上。之前我的英文准备也没有很规范，大概有以下两项:</p>
<ul>
	<li>51talk<br />
这个最有趣，当时想着要提高口语, 得找一个&quot;外国人&quot;1对1演练一下。在网上找了，相中了 51tak 这个&quot;外教&quot; 1对1服务。 51talk的外教多半是东南亚赚外快的英语老师，当时办60次的月卡，一节课25块，一次25分钟, 一位 &#8220;外教&#8221; 使用 skype 或 QQ 进行 1 对 1 的英语训练。这个网站是瞄准了广大平民百姓的口语训练需求, 提供了物美价廉的服务。 在13年八月以来，我调整了工作日的起床时间，每天多安排了一节课，每周安排两三次，固定一位靠谱的老师。 长期下来感觉良好(虽然口语还是被老师批长句不行, 词汇不够)。如果有想要购买他家服务的同学可以找我沟通，我还有 120 节课没有用完。。。</li>
</ul>
<ul>
	<li>friends<br />
一个快速提高英语的方法就是看英语电影或连续剧, 这里老友记确实很不错, 既休闲又能培养听力。身边有不止一个小伙伴说看了不下一遍的。</li>
</ul>
<h3>专业技能</h3>
<p>专业技能方面我的准备也是略仓促，导致了在一些公司的求职失利。认真去准备一般即可有收获。大部分公司都考算法和数据结构，并且在几乎所有北美公司这部分都占了很大的比重。<br />
简单粗暴的说法比如，经常会有拿offer的同学说，&quot;leetcode 刷两三遍就够了，常见题目也就都看过了。&quot; 确实是这样。</p>
<ul>
	<li><a href="https://oj.leetcode.com/">leetcode</a><br />
leetcode上的题目实在太经典了，做法多样，确实可以刷上两三遍。那么刷两三遍要达到什么目的呢? 给你一道leetcode的原题你能够短时间一次性完成, 尽量少犯错误，一步到最优做法，以及明白各种扩展。 github 上有很多人share leetcode 的切题记录可以参考, 官方论坛的讨论也都很不错。之前看到 <a href="http://pan.baidu.com/s/1kTj0Dy3">一个比较老的对leetcode 的题目的难度以及面试出现频率做了统计的表格</a> 可以参考一下，有侧重的刷题。</li>
</ul>
<p>除了 leetcode, 有一份 mitbbs 整理的 <a href="https://github.com/lanxx019/mitbbs-iq">面经题目综合文档</a> 也不错，很有参考价值，类似 &#8220;历届真题&#8221; 的感觉。这里不仅有纯算法题，还有一些逻辑，概率，设计题。 察实际工程实践抽象出的设计问题，这往往是比能够通过机械训练达到熟练的算法问题来的更难的更有区分度的。这方面我的积累深度还不够，也吃过亏。这部分感觉还得看个人工作中的总结与归纳，就不展开了。</p>
<h3>Resource</h3>
<ul>
	<li><a href="http://blog.liancheng.info/about.html">连城</a>
	<ul>
		<li><a href="http://developer.51cto.com/art/201304/387673.htm">北美求职记</a></li>
	</ul></li>
	<li><a href="http://about.me/catchen">Cat Chen</a>
	<ul>
		<li><a href="http://chinese.catchen.me/2012/06/blog-post.html">理想的技术面试过程</a></li>
		<li><a href="http://www.cnblogs.com/cathsfz/archive/2012/11/05/facebook-interview-experience.html">面试体验：Facebook 篇</a></li>
		<li><a href="http://chinese.catchen.me/2012/08/google-interview-experience.html">面试体验：Google 篇</a></li>
		<li>赴美工作常识
		<ul>
			<li><a href="http://chinese.catchen.me/2013/05/to-work-in-the-us-part-1-visa.html">visa</a></li>
			<li><a href="http://chinese.catchen.me/2013/07/to-work-in-the-us-part-1-application.html">application</a></li>
			<li><a href="http://chinese.catchen.me/2013/08/to-work-in-the-us-part-3-english.html">english</a></li>
			<li><a href="http://chinese.catchen.me/2013/09/to-work-in-the-us-part-4-interview.html">interview</a></li>
		</ul></li>
	</ul></li>
	<li><a href="http://blog.yxwang.me/assets/download/resume.pdf">yuanxuan Wang</a>
	<ul>
		<li><a href="http://blog.yxwang.me/2012/12/job-hunting-in-usa-2/">北美求职记（二）：Google &amp; Facebook</a></li>
		<li><a href="http://blog.yxwang.me/2012/12/job-hunting-in-usa-3/">北美求职记（三）：Hulu &amp; Twitter</a></li>
	</ul></li>
	<li><a href="http://digest.definite.name/roba-facebook-interview-q-a.html">Facebook 面试 Q&amp;A</a></li>
	<li><a href="http://www.yiyome.com/article/view/1003230-facebook-.html">FB面经集锦</a></li>
	<li><a href="http://book.douban.com/subject/5985030/">google resume</a></li>
	<li><a href="http://q.weibo.com/1312378">北美求职小组</a></li>
	<li><a href="http://www.mitbbs.com/bbsdoc/JobHunting.html"><span class="caps">MITBBS</span></a></li>
	<li><a href="http://hawstein.com/posts/ctci-solutions-contents.html">Cracking the coding interview</a></li>
</ul>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[意外的好运]]></title>
    <link href="http://code6.github.com/blog/2014/07/15/serendipity/"/>
    <updated>2014-07-15T09:43:00+02:00</updated>
    <id>http://code6.github.com/blog/2014/07/15/serendipity</id>
    <content type="html"><![CDATA[<p>昨天 <a href="http://xiaolai.li/about/">笑来老师</a> 来鄙厂做分享来着, 讲的挺好的, 趁着记忆还热乎赶紧发出来。
很早以前就通过<a href="http://book.douban.com/subject/3609132/">把时间做朋友</a>认识笑来老师了(惭愧的是这本书还没有看完), 去年又看到他自学 rail 搞了一个还不错的创业产品 <a href="http://knewone.com/">knewone</a>, 感慨跨界神人也，今天在跟别人闲聊的时候才知道他是比特币大咖，四大天王之首, 顿觉此人太神了。盲目的崇拜是不好的，不过汲取一些成功的经验是有益的。</p>

<p>以下简写笑来老师为 xl。</p>

<h3><strong>Serendipity</strong></h3>

<p>开场提到了一个有趣的单词，<a href="http://en.wikipedia.org/wiki/Serendipity">Serendipity</a>, 中文即是意外的好运，据说这个单词曾被翻译公司认定为十大最难翻译的词之一。<br/>
可以认为本次的分享通篇都围绕着意外的好运这个主题，通过各种真实案例来推导一个主题:</p>

<blockquote><p>意外的好运可以创造。</p></blockquote>

<h3><strong>把时间当朋友</strong></h3>

<p>有人提到为啥在新东方教学之后会写把时间当朋友这本书，xl解释到这是他在新东方教书的经验之谈，并且总结后发现这不仅仅是在学英语这件事上，这是一种 <strong>凶悍</strong> 学习方法论，也是他多年来坚持的学习方法。
提到这些年他的这些好运，&#8221;不是偶然的，而是一定会发生的。&#8221; 他这么说的。略嚣张，不过有嚣张的资本就显得很酷了。</p>

<h3><strong>信息过滤</strong></h3>

<p>在提到信息过滤这一点，xl是挺不屑的。他介绍了他使用 twitter 的经验: <strong>fo 了18k人</strong>。
看到这个可能会觉得很不可思议，当然，如果你是一个个fo 的话那确实太吓人了，没错，他就是自动化fo的。
这样会导致 <strong>信息过载</strong> 问题? 这里他提到一个观点:</p>

<blockquote><p>信息过载是无法解决的，该解决的问题是垃圾信息过滤</p></blockquote>

<p>那么这 18k 的fo量，该怎么做信息筛选呢?<br/>
肯定得有靠谱的工具才行，这里xl 推荐了 <a href="hootsuite.com">hootsuite.com</a>, 看了一下, 是一个twitter的客户端，不过目前看起来支持导入很多 sns 的feed。xl 提到他有一个宽屏的显示器，然后开着 hootsuite 并且做多个strem做各种关键字的filter，或者筛选一批foer来看。<br/>
那为啥要费大力气暴露在这么多信息面前，然后再做过滤，而不直接就选择自己感兴趣的人来fo呢?<br/>
这里主要阐述了一个思想:</p>

<blockquote><p>不挑，不做预先筛选</p></blockquote>

<p>这里xl 举了两个例子，一个是借鉴了计算机大师的名言:</p>

<blockquote><p>过早的优化都是有害的。</p></blockquote>

<p>另外一个是扯了一下 &#8220;剩女&#8221; 是怎么剩下的， &#8220;算数没算好。&#8221;, 筛选过多导致符合条件的人数小于一生中能遇到的熟人的数量。</p>

<h3><strong>好学不挑</strong></h3>

<p>这是我概况的意思。在扯到信息过滤，不预先筛选后。xl 提到自己兴趣广泛, 做事都是基于学习的乐趣，所以很有动力。<br/>
谈到跨界这个问题，有很强的学习能力并花足够多的时间去钻研，这就谈不上跨界了，所谓 <strong>行者无疆</strong>。 这里态度很关键，不能抱着随便的心态，就这一点他谈到当初很多人一起关注了比特币，但是大部分人都是玩玩心态，买卖几个币罢了，而他做足了功课下大力气投资，收获了这个意外的好运。大部分抱着玩玩的心态其实主要是真正的钻研学习都是不轻松的。 写到这里我其实挺好奇他是怎么找准方向，并能这么有精力去学习的。<br/>
那么该怎么学习呢? <br/>
这里有几条tip:</p>

<ul>
<li>假装会</li>
<li>加倍努力</li>
<li>足够的耐心</li>
</ul>


<p>第2,3点都比较容易理解，第1点其实我没太明白。假装会把自己骗过去有什么意义呢? xl 提到可以在这个前提上来思考会的人的学习方式, 反过来理清楚到底有哪些需要补充学习的地方。</p>

<h3><strong>但行好事，莫问前程</strong></h3>

<p>这部分即是说执行这样一套方法论不能太有目的性, 意外的好运总会发生的。这跟我前段时间一直挂在嘴边的一句话 <strong>谋事在人，成事在天</strong> 挺像的。之前我的理解是把各种我能做的事情做了，剩下的就靠上天，靠一点运气了。在这一块 xl 还是举了挺多无心插柳的例子来支持他的观点的。</p>

<h3>感想</h3>

<p>大概如此，部分多了我的解读，可能有遗漏，曲解了些许意思。后来翻了 <a href="https://ruby-china.org/xiaolai">xl 在 rubychina 论坛的发帖记录</a>, 感觉之前没线下接触一下这个神人多少有点遗憾。<br/>
目前我还没有掌握一门可以快速开发 app / 网站的 语言，除了公司的项目的话，没有开发过个人项目，虽然感觉这一切其实都不难的，但还没迈出这一步。看到 xl 老师这么牛逼的跨界，作为程序猿真感到羞愧。<br/>
知耻而后勇。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IPSC 2014]]></title>
    <link href="http://code6.github.com/blog/2014/06/16/sucker-punch-at-ipsc-2014/"/>
    <updated>2014-06-16T23:00:00+02:00</updated>
    <id>http://code6.github.com/blog/2014/06/16/sucker-punch-at-ipsc-2014</id>
    <content type="html"><![CDATA[<p class="date">2012-06-16</p>
<p>今年的ipsc 昨天刚结束，跟3xian 和 larry 一起在3xian家，晚上七点到十二点，做得挺过瘾的。我们的队名是 <code>Sucker Punch</code>, 最终104名，b1 在最后节骨眼没有搞出来，还是有希望挤进前100的。下面简单记录一下比赛的经过吧。</p>
<p><img src="http://code6.github.com/images/ipsc_2014.png"></p>
<p><strong>Problem C: Copier</strong><br />
这道题挺虎的，说的是最初把一个1到N排列每次一段连续子串拷贝到右边，重复若干次后求原始排列。一开始我想暴力小数据来着，有若干限制。不过一看大盘不对，b2都好多人过了，然后想了下，发现从左到右数字的出现顺序没有变，于是瞬秒了。</p>
<p><strong>Problem H: Hashsets</strong><br />
这道题即是让你给50000个数字，然后让c++/java 的 hashset 插入超过两秒/十秒。 3xian 没过一会就丢来一个 <a href="http://codeforces.com/blog/entry/4876">样例程序</a> ，照着搞一下就过了小数据= = 不过看起是针对java的，于是就没有交大数据了，大数据需要 c++/java 均超过10秒。看solution 看到一个 <a href="http://en.wikipedia.org/wiki/Universal_hashing">universal hashing</a></p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[To Be An Ac Man]]></title>
    <link href="http://code6.github.com/blog/2014/04/09/to-be-an-ac-man/"/>
    <updated>2014-04-09T11:30:00+02:00</updated>
    <id>http://code6.github.com/blog/2014/04/09/to-be-an-ac-man</id>
    <content type="html"><![CDATA[<p>清明回学校一趟跟集训队的小伙伴做了一个小分享，主要是讲了一下我对做一个好的acmer 的理解，准备的稍显粗糙，slide 上的内容也多为大空话。anyway，share给大家，求指导。</p>
<p><iframe src="http://www.slideshare.net/slideshow/embed_code/33304317" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/code6/being-a-good-acm-player" title="如何做一个好的acmer" target="_blank">如何做一个好的acmer</a> </strong> from <strong><a href="http://www.slideshare.net/code6" target="_blank">code6</a></strong> </div></p>
<p>另外吐槽一点就是 slideshare 居然被强了，太没天理了。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Big Cube]]></title>
    <link href="http://code6.github.com/blog/2014/03/15/big-cube/"/>
    <updated>2014-03-15T23:52:00+01:00</updated>
    <id>http://code6.github.com/blog/2014/03/15/big-cube</id>
    <content type="html"><![CDATA[<p><img src="http://code6.github.com/images/big_cube.jpg"></p>
<p><code>Big Cube</code> 是今天(2014.3.15) 鄙厂第二届黑客马拉松我们队的作品, 我跟 yc 还有 cc 一起搞的。这个名字是我今天随便取的，我们要做的是一个 <span class="caps">OLAP</span> 的 demo。</p>
<p><strong>前情提要</strong></p>
<p>早在12年初我们就在寄希望 <span class="caps">OLAP</span> 来帮助数据仓库数据建模，数据解读与分析。当时我们采用的是 <a href="http://community.pentaho.com/projects/mondrian/">mondrian</a> 当时的想法很理想，感觉就是创建几个模型，几个维度，事实，就可以在各种粒度下把各种指标囊括进来，并有统一的地方可以管理指标定义。 后面这个项目失败了，diao总结了一些失败的原因:</p>
<blockquote>
<p>开发和使用太复杂， 成本太高<br />
产品成熟度较低， 很多数据需求没法支持<br />
笨重，不太适应互联网公司快速灵活的节奏</p>
</blockquote>
<p>在我看来，当时采用的工具和方案主要还是太慢了，不仅是工具调研与应用，后期的模型开发以及工具使用同样。由于公司发展很迅速，大部分模型都不太稳定，新的事实，维度也经常产生，维度和事实本身也太稳定，部分事实发生之后还会修改。当时的 backend 依赖的是 mysql ，本身也不可扩展。</p>
<p>后来 ek 又启动了一个曲线救国的计划，ModelBuilder。这个工具是 ek 独立完成的一个跟 <span class="caps">ETL</span> 工具相结合的模型设计工具，通过配置模型可以在hive下生成各种主题各种聚合粒度下的统计指标。在我看来相当于一个自研的 <span class="caps">OLAP</span> 服务的核心部分。现在在内部使用也很好，负责的指标和依赖很多。</p>
<p>当然这次 Hackathon 我们使用的是 <a href="http://cubes.databrewery.org/">cubes</a>  这个开源的 <span class="caps">OLAP</span> python 包搭建的。早在 12 年我们做 <span class="caps">OLAP</span> 的时候，我就发现这个 python <span class="caps">OLAP</span> 工具, 不过当时也只是关注，一直都没有尝试使用。这次比赛之前又看了一下，感觉拿来主义十分方便，简单的模型配置还附赠一个前端的模型展示 <a href="https://github.com/jjmontesl/cubesviewer">CubesViewer</a> , 之前提到如果 backend 依赖 mysql 的话，那看起来还是不够完美，所幸 cubes 的 backend 是可以定制化的，其中 sql 类型的 backend 支持所有封装了 sqlalchemy 接口的引擎, 恰巧我们最近上线了 <a href="http://prestodb.io/">Presto</a> , 看了一下 github，有人已经提供了 Presto 的 sqlalchemy 封装的包 <a href="https://github.com/dropbox/PyHive">pyHive</a> , 看起来万事俱备了，于是我确定了 Hackathon 就搞这个吧，一个支持海量数据快速响应的 <span class="caps">OLAP</span> 服务 demo。</p>
<p><strong>准备工作</strong></p>
<p>在 Hackathon 的前几天我主要是负责前期体验的，这里我想搞清楚的是:<br />
1. 模型表示上是否可以与我们的数据格式对接(或者需要生产新的数据来适应特定格式), 需定一个展示模型，最好有意义 <br />
2. presto backend 开发是否有问题(接口是否好用), presto 的SQL语法十分支持cube生成的查询<br />
3. cube server 的性能是否符合预期<br />
4. 前端是否需要再做进一步开发</p>
<p>在13号左右我开始在线下测试第一个 presto backend 的 &#8220;hello world&#8221; 的case, 发现生成的语句会包含 <code>order by limit offset</code> 的语句，而 presto 不支持 offset 类型的语句, 算是我们后续要解决的一个问题吧。其他问题基本没来得及看。</p>
<p><strong>开幕</strong></p>
<p>15号下午五点如期开场, 兴哥和荣均简单地做了讲话大家便更忙各的了。</p>
<p><strong>14号进展</strong></p>
<p>开始后我们把晚饭定完之后就开始分工着手解决问题, 这里我主要负责模型的选择与数据生成以及配置相关工作, yc 负责 cubeviewer 的适配，cc 负责 presto 相关的查询支持。我们就在自己工位上搞，一起通过 <a href="http://code6.github.com//github.com/code6/cubes/tree/hackday">github</a> 共享代码。一开始我打算配置一个较复杂的模型，不过深入去看，感觉还是得一步一步来，先搞定简单的才是, 于是我选择了一个仅有四个维度的已经聚合过的数据作为展示demo。 presto 这边纯爷着手解决 offset 的问题，兴致挺高的，打算在 presto 那边添加这个功能。yc 同学由于要去签租房合同，搞了一会儿就得提前撤了。话说这次我们定的是棒约翰的披萨外卖，挺好吃的，我一下子吃的有点撑。晚上十点我跟cc一起坐班车回家了, 我的进度是配置了一点点模板，cc还在解决 offset 的问题。这里我说的是这次我没有像上一届一样在公司通宵搞这个了，这段时间我一回到家就洗个澡感觉十分舒服，洗完澡之后可以支撑我工作到两点，然后第二天早上七点起来还很有精神。所有我在 Hackathon 也选择回家，洗澡然后第二天再过来。</p>
<p><strong>15号进展</strong><br />
由于 demo 还没有成型，15号早上我六点就醒了开始干活了，感觉 presto 那边做修改可能比较困难，我就在 cubes 这边生成查询时将 order 和 limit 相关子句给去掉了, 算是做了二手准备吧，这样我们的一个简单 demo 才跑了起来。早上七点半我就出发去公司了, 十分兴奋。后面十点多的时候我们三个都到了，大家继续战斗，我让 cc 来一起配合模型编写以及一些前端展示的润色工作，yc 同学还在搞 cubeviewer, 后面他发现一个大bug : <a href="https://github.com/jjmontesl/cubesviewer/issues/23">cubeviewer 使用的 cubes api 跟最新的 cubes 不兼容</a> ，当时差点崩溃了。 yc 同学说，&quot;给我两个小时，我把这个bug fix 一下&quot; 。后面 yc 还真的在约定时间内搞出了 api 把 cubeviewer 跑起来了。我们在一旁帮忙测试，发现还是有几个问题:<br />
1. 维度数据没有正确展示<br />
   这部分初步猜测是由于 cubeviewer 使用的数据格式同样是老的，导致部分假设面对新的数据格式失效了，导致维度相关数据没有正确展示。<br />
2. 做 filter 的模块没能正确执行<br />
   这里我们后面发现是由于 filter 模块的 <span class="caps">SQL</span> 模板产生的 <span class="caps">SQL</span> 不符合 presto 的语法规范，导致发起的执行失败。</p>
<p>或许还有更多的问题，不过以上两个问题的解决就很花我们的时间了，最终在下午两点半之前也没能很好解决，时间到了，只能硬着头皮上台演示了。</p>
<p>我们抽到了第四个演示，我简单做了四页 ppt，又开了两个查询页面展示我们的 demo，不过可能是演讲技巧的问题，异或展示demo不够清楚，感觉整体展示效果不好。后续我在台下听了后面二十来组的作品，大家的想法都挺出彩的，完成度也很好, 比上一届来说进步了很多。最终我们毫无悬念地没有拿到奖项，anyway，我觉得能在短短的比赛时间内让最初的想法 work 我已经很满意了，后续还可以在这个点上继续开发，可以期待后续给用户提供这样遍历的分析引擎是非常牛逼的。</p>
<p><strong>后续改进</strong></p>
<ul>
	<li>将 cubeviewer 调通, 调整 sql backend 查询语句生成让  presto 支持相关查询</li>
	<li>测试 model viewer  &amp; model builder 组件, 方便观察和编辑model，可以做到自动 reload model 文件那就再好不过了。</li>
	<li>添加 label, 多语言支持(主要是中文)</li>
	<li>在适当的地方添加 cache</li>
</ul>
<p><strong>总结</strong><br />
本次 Hackathon 由于有强大的队友的加入，再加上确定的计划与目标，故一切尽在掌握当中。当然时间还是没能有剩余，没能达到最佳状态。我看有些组的作品其实也不全是这两天的工作，不过感觉也无可厚非，毕竟牛逼的想法本来也不是一天之内就可以很好的 prototype 出来的。下次也许我们也可以这样来，多做一些准备工作，尽量想清楚所有可能出问题的地方以及相应的解决方案，这样在实际动手时才不会慌张。</p>
<p><strong>后记</strong><br />
又看了多年之前的 mondrian, 发现现在它貌似也很牛逼了，后端也支持很多 <span class="caps">SQL</span> backend: 支持 <a href="http://jira.pentaho.com/browse/MONDRIAN-1667">impala</a> , <a href="https://groups.google.com/forum/#!msg/presto-users/f23F-4TEeXk/aGUeDHkbW9QJ">presto</a> , <a href="http://forums.pentaho.com/showthread.php?142593-Mondrian-Redshift">red-shift</a> 。部分还属于初步阶段，不过应该也是激动人心的提高，比12年好多了。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据仓库的一天]]></title>
    <link href="http://code6.github.com/blog/2013/09/07/one-day-in-the-data-warehouse/"/>
    <updated>2013-09-07T21:15:00+02:00</updated>
    <id>http://code6.github.com/blog/2013/09/07/one-day-in-the-data-warehouse</id>
    <content type="html"><![CDATA[<p><img src="http://code6.github.com/images/a_day_in_the_data_warehouse.png"></p>
<p>标题党，&quot;数据仓库的一天&quot; 是鄙厂刚刚结束的第一届 hackathon 我们小组的项目，我，cc 和 cjz 。</p>
<p><strong>hackathon</strong><br />
鄙厂的 hackathon 在几个礼拜前就已经宣传了，不过我开始组队, 确定好做什么却是在最后几天。主要还是自己平常缺乏培养捣鼓的能力。当有得力的cc和cjz加入后，感觉我们应该可以交出一个不错的东西。在思考做什么的时候，我们已经看到有许多不同方面的创意，比如zg同学想做的 &#8220;Smart <span class="caps">SQL</span> Editor&#8221;, 章爷的类 &#8220;wolframalpha search&#8221; 的 &#8220;data knowledge engine&#8221;, diao的实时销售额展示和更多的数据可视化作品。思考初期我并不打算做什么可视化的作品，一直在想能有没有什么更有趣的想法(可视化肯定一堆人做)。不过从自己的idea pool中没有找到什么可喜的东西，后面cc提了做数据库数据流向方向的事情，其实也是可视化的东西，不过我感觉这比一大堆地图上的可视化还是更有趣了一些，当然也更难做。于是比赛前一两天我们就在一堆的数据库可视化资料中寻找适合自己的表现方式。</p>
<p><strong>前期准备</strong><br />
我们首先看到的是一个 <a href="http://www.youtube.com/watch?v=Uj5DolxL1Ak">hadoop的数据流向可视化作品</a> ，感觉还蛮酷的，不过具体细节什么的都丢失了。这里就是我的担忧: 数据的布局该如何处理。在传统的地图方面的可视化作品，作品上的每一个点都有明确的地理信息。而在我们考虑做的数据库数据的流向作品中，数据库中的数据该如何组织是个问题。这个问题我们从一开始就没有仔细考虑清楚，也不可避免导致我们最终的作品的混乱风格。在比赛前一天晚上我们看到 twitter 员工的一个不错的的hackday作品 <a href="https://blog.twitter.com/2012/visualizing-hadoop-hdfs-du">hdfs-du</a> , 在 hdfs 这个文件系统上提供一个可视化的作品, 简单但却非常实用。 另外我们看到一个可视化方面是 <a href="http://www.patrick-wied.at/static/heatmapjs/">heatmap</a> ，感觉在可视化中中添加热图的概念是锦上添花的。在这两个基础上我想到了一个改进点:</p>
<blockquote>
<p>可以在 hdfs 系统上做实时的访问展示，使用 treemap 来展示文件系统，确保展示有层次。然后实用 heatmap 来做实时的文件系统的访问热点展示，将每个时刻哪些数据被访问展示出来。这里的可以写一个异步抓取程序去抓取并分析 hdfs 上的 MR任务(可能不太全，不过具有代表性)。</p>
</blockquote>
<p>不过 cc 同学觉得 treemap 太丑了，另外比较想做数据流动方面的展示，我们在展示文件系统还是展示数据表这个基本问题上也没达成一致，于是我的建议没有被采纳。在 hdfs-fu上我们看到 <a href="http://en.wikipedia.org/wiki/Voronoi_diagram">voronoi-treemap</a> 挺酷的一个东西。我们当时认为拿那个来展示表也许是一个很酷的展示。最终我们达成一致的是 <strong>在时空两个维度上展示数据仓库的表为准，在实时的基础上尽可能添加热图和流动的概念</strong> 。</p>
<p><strong>开幕</strong><br />
就这样在一切还没有很成熟的情况下，我们在9月6号下午5点迎来了 hackathon 的开幕。</p>
<p><strong>前期</strong><br />
开始简单的分工是我搞后台数据支持，cjz 搞heatmap/射线相关的研究 , cc 搞前端展示支持。我一开始先准备基础数据，比如表信息以及依赖关系，这些东西从元数据中是很方便获取到的。与此同时cc同学调研 voronoi diagram 的展示，希望能将所有表展示在这之上。当我们做到第二个小时的时候，cc 发现 voronoi 似乎不太能胜任, 似乎这个图不太能表现表的大小关系(虽然此时我还没有取到这个数据)。当时我们认为不能取到大小关系是不能接受的，于是我们转向其他的展示。cc 后面考虑使用 <a href="http://ramblings.mcpher.com/Home/excelquirks/gassites/d3nodefocus">d3 的force layout 的一个 node 展示</a> 。这段时间就是我跟cc在初始化数据上的一些联调, 由于数据量实在太大，调了很久也没有很满意的展示。cjz 那边 heatmap 看起来很方便使用，不过射线的话暂时没想好怎么搞, 而cc 找到的一个可视化作品 <a href="http://artzub.com/d3/wbca/">wbca</a> 实在太炫了，也让我们非常想尝试添加上射线。 两个小时后我主要是在提供所谓数据流向方面的数据，这部分我一开始是简单做的，跟 cc 简单商量我来提供一个时间段内发生的数据移动事件。由于我们要展示所谓热度这个概念，于是这里得定义一下。前期简单做的话我直接使用ETL相关日志，通过ETL来还原表级别的数据流动。将当前时刻正在进行的ETL流程找出来，并跟进执行位置确定执行百分比，后续可以以这个百分比来做热度数据。其实这里热度的定义并不准确，没有太多含义，仅仅是为了展示做了一个相关的百分比罢了。我简单将数据提取出来后，观摩了一下 <a href="http://flask.pocoo.org/">python 的 flask</a> 做了一个简单的api服务。这里我并没有马上就考虑实现实时的部分，而是打算看到第一个 demo 再说。</p>
<p><strong>第一个demo</strong><br />
我们实际上做出第一个demo的时间比预期的晚很多，我在后端方面的粗糙工作很快就完成了，而前端关于热图和射线方面的问题还比较多。这段时间我基本没有产出，这是本次比赛的一大败笔，我没想好这段时间该做什么，现在看起来也许是反思一下我们的目标定制是否有问题，一些概念是否有问题(比如热度)，是否需要及时修正。在呈现第一个demo的时候还有一个小插曲，由于 js 不能跨域访问，我跟cc的前端作品必须揉在一起。于是我在找 <a href="http://segmentfault.com/q/1010000000171098">flask 如何访问静态文件上费了一番功夫</a> , 这里让大家看笑话了，主要是我平时总觉得这种东西肯定很方便google到，临时去找的时候搞的手忙脚乱。在大约第7个小时左右我们才有了第一个demo:  <strong>随着时间流逝展示数据仓库一天中表的热度(其实是访问情况)</strong> 。 展现效果并不好，没有实时，没有射线，热图展现过卡, 更多的还是数据layout不太好。这个时候大家还是在想如何把前端展示搞得更好，都扑上去搞前端了，没有冒出其他想法和其他改进。现在想想当时我可能应该往实时数据支持方面考虑一下，这样可能会跟加分一些。</p>
<p><strong>射线没有搞定</strong><br />
在尝试一番无果之后，我们关于射线的展示宣告失败。这时候感觉士气不是很好，我们展现的只是一个一大堆圆圈然后随着时间变化的热点。关键是这里没法说故事，这里的热点没法自解释。这段时间我主要是帮他们做点前端打杂，比如添加一下title，添加一下热点label, 添加一个当前时间什么的。cc和cjz还在研究射线相关的技术问题，最终没有搞定。看起来我们只能交一个半成品了。在第二天早上cc希望尝试删减表来达到获得更好的数据布局，不过数据过少时整体展示也不美观，没有达到希望达到的层次效果。后面我们基本没有动力做其他改动了，时间也很快过去。</p>
<p><strong>比赛结束</strong><br />
在7号下午两点比赛最终结束了，我们基本以第一个demo的状态结束了本次比赛，有点无奈。本次我们在前后端的配合出现明显的问题，主要原因还是作品的展示定位过于高端，为了达到炫丽的效果需要深厚的前端经验。后面在作品展示时，观看其他组的数据可视化作品, 虽然不够炫目，但在细节方面都有细心刻画，反观我们自己就是一团乱麻。hackathon 除了可视化方面还有其他很有趣的作品，其中不乏解决了公司实际面对的问题的作品，也有很多产品,rd组合的创意产品产生。Anyway, 这是我们第一次 hackathon 比赛经历，有一个有点挫但是能用的 demo ，enjoy yourself即可。</p>
<p><strong>心得</strong><br />
若说有什么心得，我想了想有以下几点:</p>
<ul>
	<li>提前想清楚，确定定好做哪一方面的事以及一些重要问题的提前准备，达成一致。</li>
	<li>在做的时候需要不断沟通，当遇到困难时如不能及时解决得想办法折中，调整方向。</li>
	<li>数据可视化产品需要设计，不能马虎。</li>
</ul>
<p><strong>后续可以做的改进</strong><br />
列一下几个可以改进的地方:</p>
<ul>
	<li>实时访问<br />
一开始我们是希望做成实时的数据展示，不过最终没有去做罢了，这部分并不难。不过想到这里我感觉似乎这里&quot;流动&quot;不是很好表示了，而热图倒是完全适用，这跟我最初的设想一致，不过从文件系统下降到数据库的表罢了，这层下降可能在业务层面上会更直观。</li>
</ul>
<ul>
	<li>寻找更好的数据组织方式<br />
数据组织方式还是一大痛点，太多的表只会带来混乱。</li>
</ul>
<p><strong>Ref</strong><br />
<a href="http://heatmapdemo.alastair.is/">A day in the City</a><br />
<a href="http://artzub.com/d3/wbca/">wbca</a><br />
<a href="http://tweetping.net/">Tweetping</a></p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Beijing Sucks at ipsc 2013]]></title>
    <link href="http://code6.github.com/blog/2013/06/10/beijing-sucks-at-ipsc-2013/"/>
    <updated>2013-06-10T02:14:00+02:00</updated>
    <id>http://code6.github.com/blog/2013/06/10/beijing-sucks-at-ipsc-2013</id>
    <content type="html"><![CDATA[<p>今年的 ipsc 最早是跟毛哥说好要做的，后面 3xian 邀请搞一搞线下玩, 本次我们取了队名 &#8220;Beijing Sucks&#8221;, 简称bs。<br />
在五月底的时候得知毛哥云游四海去了，不能参加线下比赛，于是只能再找他人拼团，最终决定的是在清华读研的 dumbear, 后面dumbear 也在本场比赛中发挥了异常关键的作用。<br />
ipsc 正式比赛在 6.8 号，虽然是周六，但要上班。由于我刚好也想准备一下其他事情，就把最后半天年假给请了。六点之前，我们到达了3xian的窝，不一会儿比赛就开始了。<br />
一开始3xian看前面，我看中间，dumbear看后面。A 和 H 很快有人过了。</p>
<p>[<span class="caps">TODO</span>]</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[keep updating your cv]]></title>
    <link href="http://code6.github.com/blog/2013/04/15/keep-updating-your-cv/"/>
    <updated>2013-04-15T00:59:00+02:00</updated>
    <id>http://code6.github.com/blog/2013/04/15/keep-updating-your-cv</id>
    <content type="html"><![CDATA[<p class="date">2013-04-21</p>
<p>2013.7.26 update<br />
知道什么呢，这件事情我直接拖了三个月，哦，这三个月我都干什么了，真该封我为拖延症冠军啊。 anyway, 还是继续写吧， move on。希望这次可以写完。</p>
<p>有一种观点我很赞同，就是要持续更新你的简历。</p>
<h3>为什么要持续更新简历呢?</h3>
<p>首先做一件持续的事情很cool，有积累，有收获。<br />
维护一份简历可以让你看到工作概括，看到与牛人的差距( <a href="https://news.ycombinator.com/item?id=4472835">always benchmark against the best</a> )。<br />
维护一份简历可以让你在找下一份工作时不会手忙脚乱。<br />
&#8230;</p>
<p>在毕业之前我总共制作了中/英文两个简历, 其中中文是用 word 制作的，英文的话是用学长留下来的 latex 模板制作的。在找完工作后我基本没有维护过简历了。作为一个希望能够持续总结的人，面对着停留在两年前毕业的简历，感觉是不能忍了。 我们不仅要认同一种观点，还要亲身去实践才算, 于是我开始实践更新简历这件事情(从写下这句话的三个月后，god)。</p>
<h3>如何更好/方便地维护简历呢?</h3>
<p>要做到定期维护简历的话，每次更新简历的代价就不能太高。良好的简历维护应该能够做到:<br />
关注内容而不用在意展示<br />
最好是文本编辑，方便版本控制和追溯</p>
<p>latex 版的简历看起来赏心悦目, 不过制作起来稍显复杂, 也不容易维护(latex菜鸟意见= =)。word 就更不用说了，排版不是很容易，也很难做版本控制。<br />
考虑维护简历这是一个长期的过程，我希望更新/生成简历能尽可能快且保持高质量。<br />
于是我考虑是否能用 markdown 来写简历呢。  确实发现很多文章介绍用 markdown 来写简历。</p>
<h4>使用 markdown 来制作简历</h4>
<p>鉴于有使用 markdown 的习惯，于是很自然地考虑到使用 markdown 来写简历，最开始在 github 上看到 <a href="https://github.com/mwhite/resume">mwhite的resume</a>  项目看起来还不错。这里使用到一个好东西，叫 pandoc，可以在不同文件格式之间转换。比如只写了markdown 版本，可以转换成 html/latex, 看起来挺方便的。不过原仓库的排版不太喜欢，改起来又似乎有点麻烦。 同样还有一个 icco的 <a href="https://github.com/icco/Resume">Resume</a> 也是同理，写 markdown 然后 host 到 github 上之类的, 相比之前其排版会相对美观一点。<br />
编写 markdown 可以直接在 vim 中敲敲打打，也可以是用  <a href="http://mouapp.com/">Mou</a> ，一款十分好用的 markdown 编辑器。</p>
<h4>markdown 有什么问题呢?</h4>
<p>我遇到的问题是难以把漂亮的 markdown 转化成 漂亮的 pdf，直接从 markdown 转换成 pdf 会出现各种边距问题。在努力尝试一番未果时，后面我退回到 latex 了= = 不仅做 markdown 还做 latex, 然后 pdf 版本简历还是用 latex 出吧。mac 上我安装了 <a href="http://tug.org/mactex/downloading.html">mactex</a> 来编写 latex, 基本的节奏还是在找比较好的模板，然后填上自己的内容。</p>
<h3>如何编写你的简历?</h3>
<p>当工具本身的选择搞定，剩下的就是内容和排版了。<br />
在内容方面， <a href="http://dreamrunner.org/wiki/public_html/Books%20Review/%20Interview/The%20Google%20Resume.html#sec-3">google reusme</a> 第四章中给出蛮多中肯的建议。<br />
工作经历是简历中一个重要组成部分，在介绍过往工作时, 要注意以下几点:<br />
<code>成就导向</code><br />
主要以你完成了什么而不是介绍你在做什么，这里即突出你的贡献而不是你的职责, 而且应着重突出重要贡献(bullet)。<br />
<code>量化结果</code><br />
量化你的贡献，用数据说话。</p>
<p>至于排版方面, 有几个建议:<br />
<code>干净, 专业，一致</code><br />
体现在统一间距和对齐上，简单来说就是要看着漂亮，顺眼。<br />
<code>控制在一页简历</code><br />
简历控制在一页纸上方便阅读，太长后面部分基本也没有pv。只放最相关的重要部分。<br />
<code>突出亮点主题</code><br />
理论上越有亮点的部分放越前面效果越好，但考虑到主题前后条理性还需要做一些适应性调整。一个明显的例子是如果教育经历不是很出彩，可以考虑将其往后挪。</p>
<p>当然以上几点我也基本没完成，只是比较赞同。</p>
<h3>我的成果</h3>
<p>初步做了 <a href="https://github.com/code6/playground/blob/master/resume/cv_md/code6_en.md">markdown版本</a> 和 <a href="https://github.com/code6/playground/blob/master/resume/cv_latex/v2/code6_v2.pdf">latex版本的简历</a> , 目前 <code>Experience</code> 展开略细，还需进一步改进。 简单观察，很容易就发现目前我简历的问题:<br />
工作没有亮点, 参与而不是推动<br />
技术能力没有杀手锏<br />
没有个人项目</p>
<p>没有做得很漂亮，发现问题就想办法去改进吧:)</p>
<p>ps:<br />
又是一件拖延了很久的事情，大概是从今年二月份开始就想做了，每天对自己念一遍我要把这件事情搞定，于是可以搞定，感谢sean。</p>
<p>Ref:<br />
<a href="http://bitlyfied.com/2013/03/14/markdown-cv/">markdown-cv</a><br />
<a href="http://cmwelsh.com/beautiful-resumes-with-markdown-and-latex">beautiful-resumes-with-markdown-and-latex</a><br />
<a href="http://dreamrunner.org/wiki/public_html/Books%20Review/%20Interview/The%20Google%20Resume.html#sec-3">google reusme</a><br />
<a href="http://shenfeng.me/resume/index.html">shenfeng&#8217;s cv</a><br />
<a href="http://mijia.org/cv">mijia&#8217;s cv</a><br />
<a href="http://blog.devep.net/virushuo/2005/06/06/1118072629843.html">如何做简历</a></p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[query evolution]]></title>
    <link href="http://code6.github.com/blog/2013/04/04/query-evolution/"/>
    <updated>2013-04-04T11:52:00+02:00</updated>
    <id>http://code6.github.com/blog/2013/04/04/query-evolution</id>
    <content type="html"><![CDATA[<p class="date">2013-04-04</p>
<p>从最原始的查询开始，位于后台某个报表，当用户发起一个查询，我们该干啥呢?</p>
<p>抽象一种最简单的形式，查询是对我们的数据做一定的转换而得来的，即</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/all_data_function_query.jpeg"></p>
<p>按这样的理解，当用户发起一个查询时，我们可以直接在原始数据集上进行操作, 操作的过程可以在服务端或者客户端。</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/all_data_function_query_2.jpeg"></p>
<p>直接在原始数据上操作查询数据是非常艰难的，业务方面的数据并不是那么查询友好，有多个查询需求时得重复很多重复的代码和计算。</p>
<p>于是我们很容易想到上述的模型需要再添加一层预处理层，方便查询。</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/add_precompute_view.jpeg"></p>
<p>在实际处理当中，我们本着依靠数据仓库理论武装自己的原则，对原始数据做了系统的预处理后形成了一个数据仓库。</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/precompute_in_dw.jpeg"></p>
<p>由于引入了预计算，就有了一个数据更新问题。为了抠那一点时间和空间，我们绞尽脑汁想到了一种所谓增量更新( incremental update)的方法，于是数据愉快地更新起来了。</p>
<p>机器或者人工的失误，数据源数据发生了错误或遗失，对于我们的预处理层真是一次灾难啊，没什么好说的，只能重算了。</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/incremental_update_failed.jpeg"></p>
<p>由于数据规模逐渐增加，单机的关系数据库渐渐扛不住了，我们只能引入分布式的处理(mapred)来分担预处理的压力。</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/switch_to_hadoop.jpeg"></p>
<p>在分布式计算模式下，原有的关系数据库特性已经不在那么好用了。索引剪枝不再好使，增量更新也不易于实现，于是大部分情况下，我们粗暴地全量计算，我们再也不怕历史数据有问题了。</p>
<p>随着预处理数据渐渐地迁移，不可避免地我们需要查询分布式数据库(hive), 这样我们的查询必须支持那种异构的数据源了，我们可以再加上一层，把各类查询都接入。</p>
<p><img src="http://code6.github.com/images/query_evolution_pic/add_query_service.jpeg"></p>
<p>我们称这个新的服务是查询中心，它将作为一切查询的入口，也体现了一种服务化的理念。</p>
<p>当然，各类的查询区别明显，普通报表query 和 api 一般执行快，要求响应也快。对于用户发起adhoc 操作，则可能查询费时也不一定需要及时响应。对于这样一个包容性的服务来说是个考验。</p>
<p>似乎漏了几部分？</p>
<ul>
	<li>由于有了预处理，查询数据的实时性不可避免要打折。</li>
	<li>对于分布式数据库数据访问有点过慢(目前的策略是将聚合结果写回关系型数据库来支持快速查询)。</li>
	<li>数据应用方面，推荐/搜索相关的线上查询服务设计
	<ul>
		<li>感觉支持后台数据服务和线上服务还是不能混在一块的</li>
	</ul></li>
</ul>
<p>这些都是可改进的点，围绕着查询这个主题。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[create a python package]]></title>
    <link href="http://code6.github.com/blog/2013/01/09/create-a-python-package/"/>
    <updated>2013-01-09T00:35:00+01:00</updated>
    <id>http://code6.github.com/blog/2013/01/09/create-a-python-package</id>
    <content type="html"><![CDATA[<p>在简单做了一个类 <code>hiveserver</code> 的thrift 接口后，担心日后接口更新，我又添加了一个简单的python client包(没有照顾其他用户= =)。作为要分发给用户使用的包，我需要将其打包发布, 然后才好分发。</p>
<p>参考 <a href="http://guide.python-distribute.org/index.html">The Hitchhiker’s Guide to Packaging</a> 文档简单了操作了一下，倒也不麻烦。</p>
<p>目录结构:<br />
<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>package tree  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>.
</span><span class='line'>├── CHANGE.txt
</span><span class='line'>├── LICENSE.txt
</span><span class='line'>├── OpenHiveClient
</span><span class='line'>│   ├── client.py
</span><span class='line'>│   ├── __init__.py
</span><span class='line'>│   ├── openhive_thrift
</span><span class='line'>│   │   ├── __init__.py
</span><span class='line'>│   │   └── openhive
</span><span class='line'>│   │   ├── constants.py
</span><span class='line'>│   │   ├── __init__.py
</span><span class='line'>│   │   ├── OpenHive.py
</span><span class='line'>│   │   ├── OpenHive-remote
</span><span class='line'>│   │   ├── ttypes.py
</span><span class='line'>│   └── openhive.thrift
</span><span class='line'>├── README.txt
</span><span class='line'>└── setup.py
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>其中 <code>OpenHiveClient</code> 即为要发布的package, 其中的子目录 <code>openhive_thrift</code> 为 thrift 生成的文件。</p>
<p>setup文件内容如下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>setup.py  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">distutils.core</span> <span class="kn">import</span> <span class="n">setup</span>
</span><span class='line'><span class="n">setup</span><span class="p">(</span>
</span><span class='line'><span class="n">name</span><span class="o">=</span><span class="s">&#39;OpenHiveClient&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">version</span><span class="o">=</span><span class="s">&#39;0.1.0&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">author</span><span class="o">=</span><span class="s">&#39;code6&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">author_email</span><span class="o">=</span><span class="s">&#39;wuzhichun@meituan.com&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">packages</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;OpenHiveClient&#39;</span><span class="p">,</span> <span class="s">&#39;OpenHiveClient/openhive_thrift&#39;</span><span class="p">,</span> <span class="s">&#39;OpenHiveClient/openhive_thrift/openhive&#39;</span><span class="p">],</span>
</span><span class='line'><span class="n">license</span><span class="o">=</span><span class="s">&#39;LICENSE.txt&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">description</span><span class="o">=</span><span class="s">&#39;open hive query client&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">long_description</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s">&#39;README.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span>
</span><span class='line'><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>部分meta填写较随意，无影响。使用 <code>distutils</code>, packages一项似乎得写出所有的包，有点繁琐, 使用的是 <code>setuptools</code> , 有自带一个 <a href="http://packages.python.org/distribute/setuptools.html#using-find-packages">find_package</a> 的方法，那样写比较方便~~~</p>
<p>如果要打包的是单文件的话可以使用 <a href="http://docs.python.org/2/distutils/setupscript.html#listing-individual-modules">py_module</a> 参数。</p>
<p>后续执行 <code>python setup sdist</code> 可生成发行包 <code>OpenHiveClient-0.1.0.tar.gz</code> , 可直接使用 <code>pip install OpenHiveClient-0.1.0.tar.gz</code> 安装,  如果需要更新安装包但没有改版本号的话可以使用 <code>-U</code> 强制刷新。</p>
<p>目前敝厂没有私有pypi服务器，所以为了一个包搞一个的话没必要，一种方式是可以挂在公开的地方比如github之类的。 挂在 pypi 上的问题是不能上传覆盖相同版本号的安装包。这也很合理，应该是开发到一定程度才发布稳定版才对，跟我们在代码仓库上一修改就发布的节奏是不太一样的。</p>
<p>当然，上文都是指要做一个分发的包，如果是部署自身线上服务使用的包，完全可以直接放到代码仓库中同步到线上然后直接安装。</p>
<p>打成包的好处是将独立于业务的模块抽出来后方面引用，可以避免加上一堆 <code>sys.path.append</code> 了, 当然维护成本稍有上升。</p>
<h3><strong>附录</strong></h3>
<p>http://guide.python-distribute.org/creation.html<br />
http://woodpecker.org.cn/diveintopython3/packaging.html<br />
http://www.worldhello.net/2011/03/14/2357.html<br />
http://www.ibm.com/developerworks/cn/opensource/os-pythonpackaging/index.html</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[open hive]]></title>
    <link href="http://code6.github.com/blog/2012/12/02/open-hive/"/>
    <updated>2012-12-02T21:48:00+01:00</updated>
    <id>http://code6.github.com/blog/2012/12/02/open-hive</id>
    <content type="html"><![CDATA[<p class="date">2013-01-05</p>
<p>有时我说的话就是放屁，这已经都到 <del>12月</del> 1月了。不过我还是厚着脸皮来了，我还是希望写写的，每当我来refer自己干过的一些事情的时候, 还蛮有用的。</p>
<p>今天我想说的是近期我们在做的一个事情，说来也简单，往往我觉得难的不是要写多高深的代码，而是采取什么方式来达到一个目的, 满足需求。我的条理还有待加强，暂且这样。</p>
<p>对于做数据的团队，一个很重要的事情就是开放数据，怎样提供一个更好的环境来让更多的人来访问数据，获取他们关心的内容。如果数据始终是仅在团队内部可以使用，那么势必会增加很多重复的无谓的体力劳动。在开放数据这一块，之前大家做了一些努力，有了一个内部的自助查询的系统，面向RD和一般的分析人员。开放的方式是提供一个窗口让用户写具体的SQL来查询，返回查询结果, 并可以定制很多图表。 系统内开放了若干链接，每个链接可以查若干表，并可以看到表相关的字段信息。一般来说这样就够了，当然写SQL门槛稍稍有点高。</p>
<p>之前主要数据都是在 mysql 上，开放的方式也非常简单, 只需要提供一个从库即可, 让查询都落在从库上，然后主库进行更新。当我们在mysql撑不住，逐步迁移到hive的同时，自助查询这边相应的也需要改进以支持hive查询。虽然已经有包括 hwi( <a href="https://github.com/anjuke/hwi">anjuke的改进版hwi</a> ) 和 phphiveadmin 以及 hue(我们用apache hadoop, 用不了cloudera的产品)了，感觉跟我们自己的查询工具结合在一起会比较方便使用。结合的方式也比较简单, 简单使用hive cli的执行方式来查询并保存结果数据即可, 大致如下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>run hive query  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive -f /tmp/testsql 1&gt;testsql.output 2&gt;testsql.err
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>这样把查询结果放在临时文件中，然后再展示给用户。另外由于hive查询一般比较久，故只能做成异步查询。</p>
<p>这里为什么不用hiveserver呢? 感觉hiveserver在我们这边使用总有一些问题，使用hive 0.9 配合zookeeper时，hiveserver看起来会泄露zookeeper连接，导致一段时间后就不可用了。 当然也可能是我们的姿势不对, 不知在 hive 0.10 上是否会好些。</p>
<p>开放查询做到这一步其实基本差不多了, 用户可以自己执行查询并查看/下载结果集。 但我们在这一步的时候却还不能开放，觉得对用户的控制还不够，用户权限太大了。 说到这一点，我们目前的hadoop/hive环境上只有一个默认用户，其余用于查询的用户(比如apache)基本上对所有表都有查询权限。另外一点是我们线上的hive任务也在定期执行，自助查询这边不应该占用过多资源。在一些必要场合下我们必须有能力干掉用户的查询。简单来说，初步开放，我们需要做到:<br />
<strong>必要的权限控制</strong><br />
库/表级别，语句类型(限制只能使用select)，这些控制可以跟账号绑定。<br />
<strong>资源限制</strong><br />
任务同时可以起的map数量和reduce数量控制。<br />
<strong>锁限制</strong><br />
自助查询不能争用线上任务的锁。</p>
<ul>
	<li><strong>必要的权限控制</strong><br />
在做权限控制的时候本来想直接用 <code>hive.security.authorization.enabled</code> 参数来搞，发现当所有用户都拿一个账号(apache)来访问是没啥用的= =, 没办法，只能手动搞了，于是比较糙地搞了个类似的自己用, 表如下:</li>
</ul>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>hivetablepriv   </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="n">REATE</span> <span class="k">TABLE</span> <span class="o">`</span><span class="n">hivetablepriv</span><span class="o">`</span> <span class="p">(</span>
</span><span class='line'>  <span class="o">`</span><span class="n">grantid</span><span class="o">`</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="n">unsigned</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span> <span class="k">COMMENT</span> <span class="s1">&#39;授权自增ID&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="o">`</span><span class="n">rolename</span><span class="o">`</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;&#39;</span> <span class="k">COMMENT</span> <span class="s1">&#39;授权角色名&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="o">`</span><span class="n">dbname</span><span class="o">`</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;&#39;</span> <span class="k">COMMENT</span> <span class="s1">&#39;授权库名&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="o">`</span><span class="n">tablename</span><span class="o">`</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;&#39;</span> <span class="k">COMMENT</span> <span class="s1">&#39;授权表名, *表示任意表&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="o">`</span><span class="n">modtime</span><span class="o">`</span> <span class="n">datetime</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;0000-00-00 00:00:00&#39;</span> <span class="k">COMMENT</span> <span class="s1">&#39;记录修改时间&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="o">`</span><span class="n">status</span><span class="o">`</span> <span class="n">tinyint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="n">unsigned</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;0&#39;</span> <span class="k">COMMENT</span> <span class="s1">&#39;0为正常授权，128为已删除授权&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="o">`</span><span class="n">grantid</span><span class="o">`</span><span class="p">),</span>
</span><span class='line'>  <span class="k">UNIQUE</span> <span class="k">KEY</span> <span class="o">`</span><span class="n">rolename</span><span class="o">`</span> <span class="p">(</span><span class="o">`</span><span class="n">rolename</span><span class="o">`</span><span class="p">,</span><span class="o">`</span><span class="n">dbname</span><span class="o">`</span><span class="p">,</span><span class="o">`</span><span class="n">tablename</span><span class="o">`</span><span class="p">)</span>
</span><span class='line'><span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="n">AUTO_INCREMENT</span><span class="o">=</span><span class="mi">62</span> <span class="k">DEFAULT</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">utf8</span> <span class="k">COMMENT</span><span class="o">=</span><span class="s1">&#39;hive开放查询权限表&#39;</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>然后在实际查询的时候，使用虚拟角色来访问，解析一下查询语句使用到的表(简单正则)，然后进行一下权限判断即可。</p>
<ul>
	<li><strong>资源限制</strong><br />
这步可以很简单做，比如直接在 <code>Hadoop Fair Scheduler</code> 配置一个受限的队列即可, 基本可以保证资源限制。</li>
</ul>
<ul>
	<li><strong>锁限制</strong><br />
我们打开了 <code>hive.support.concurrency</code> 并使用zookeeper来进行锁竞争，主要是防止线上日常ETL程序执行过程中对资源有竞争(比如一个表在更新时有流程访问)，这里在自己查询避免争用线上任务的锁只需要关闭此开关即可。</li>
</ul>
<p>综上, 我们仅需把执行语句加强一下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>run hive query safely  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive --hiveconf hive.support.concurrency<span class="o">=</span><span class="nb">false</span> -hiveconf mapred.queue.name<span class="o">=</span>slow -f /tmp/testsql 1&gt;testsql.output 2&gt;testsql.err
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>另外权限控制我们在查询脚本执行查询之前做。我们还缺的一件事情是记录下用户的查询(logging)。这一步也可以简单在hive执行脚本中收集。为了能够更好的监控这些任务，我们还需要能够将查询和其所起的任务关联起来。这里使用了一个比较土的方法，就是边执行边解析程序的标准错误, 收集日志中提到的起的hadoop jobid。有了这些信息之后，就可以将一个查询所对应的任务干掉了。</p>
<p>这样我们只靠一个简单查询脚本就可以基本的给hive查询一个具有较好约束的执行环境了。这个openhive脚本可以直接给自助查询工具查询hive使用。不过对于其他RD有需求查询hive数据的，我们还得暴露一个较友好的接口，比如使用 <code>thrift</code> 做一个服务。想到这边我又想到 <code>hiveserver</code> 了, 感觉我的想法有点多余。不过还是那个问题，我们希望有更多控制，然后又不太想在hive源码上动手脚(觉得麻烦以及以后升级比较有问题, 当然主要是我对java不熟)，所以搭 <code>thrift</code> 然后背后用调用 openhive 脚本来实现, 接口可以这样:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>openhive.thrift   </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="k">struct</span> <span class="n">Query</span> <span class="p">{</span>
</span><span class='line'>  <span class="mi">1</span><span class="o">:</span> <span class="n">required</span> <span class="n">string</span> <span class="n">query</span><span class="p">,</span>
</span><span class='line'>  <span class="mi">2</span><span class="o">:</span> <span class="n">required</span> <span class="n">string</span> <span class="n">username</span><span class="p">,</span>
</span><span class='line'>  <span class="mi">3</span><span class="o">:</span> <span class="n">optional</span> <span class="n">string</span> <span class="n">password</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">exception</span> <span class="n">OpenHiveException</span> <span class="p">{</span>
</span><span class='line'>  <span class="mi">1</span><span class="o">:</span> <span class="n">string</span> <span class="n">message</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'><span class="n">service</span> <span class="n">OpenHive</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="cp"># Execute a query. Takes a HiveQL string</span>
</span><span class='line'>  <span class="kt">void</span> <span class="n">query</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">Query</span> <span class="n">q</span><span class="p">)</span> <span class="n">throws</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">OpenHiveException</span> <span class="n">ex</span><span class="p">)</span>
</span><span class='line'>  <span class="cp"># Fetch one row. This row is the serialized form</span>
</span><span class='line'>  <span class="cp"># of the result of the query</span>
</span><span class='line'>  <span class="n">string</span> <span class="n">fetchOne</span><span class="p">()</span> <span class="n">throws</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">OpenHiveException</span> <span class="n">ex</span><span class="p">)</span>
</span><span class='line'>  <span class="cp"># Fetch a given number of rows or remaining number of</span>
</span><span class='line'>  <span class="cp"># rows whichever is smaller.</span>
</span><span class='line'>  <span class="n">list</span><span class="o">&lt;</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">fetchN</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">i32</span> <span class="n">numRows</span><span class="p">)</span> <span class="n">throws</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">OpenHiveException</span> <span class="n">ex</span><span class="p">)</span>
</span><span class='line'>  <span class="cp"># Fetch all rows of the query result</span>
</span><span class='line'>  <span class="n">list</span><span class="o">&lt;</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">fetchAll</span><span class="p">()</span> <span class="n">throws</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">OpenHiveException</span> <span class="n">ex</span><span class="p">)</span>
</span><span class='line'>  <span class="cp"># Fetch Query header</span>
</span><span class='line'>  <span class="n">string</span> <span class="n">fetchQueryHeader</span><span class="p">()</span> <span class="n">throws</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">OpenHiveException</span> <span class="n">ex</span><span class="p">)</span>
</span><span class='line'>  <span class="cp"># Fetch all query log</span>
</span><span class='line'>  <span class="n">string</span> <span class="n">fetchQueryLog</span><span class="p">()</span> <span class="n">throws</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">OpenHiveException</span> <span class="n">ex</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>整个接口基本是 <code>hiveserver</code> 的子集= = 服务端简单使用Python来搞，使用thrift的 <code>ProcessPoolServer</code> 类 ，其原理是server启动时fork出N个工作进程，进程之间不影响且可以重复使用。 这样遇到的问题是服务器的处理有瓶颈，每次最多同时处理N个任务，来多了会阻塞，目前我暂时将N设置为10。后续完全可以做成异步的形式，当然得修改接口，比如添加一个 <code>sessionid</code>  的概念。后来跟同事商量，其实对于hive查询本身server端是没有什么压力的(主要在hadoop集群上), 故基本不需要考虑 <code>python GIL</code> 问题而使用多进程。另外他建议使用 <code>gevent</code> 来提高server的并发能力，当然这样瓶颈就落到后端查询上了，感觉还是需要一个队列的机制，倒是可以试试。</p>
<p>大概就是这样了，废话了很多其实内容很少，也很简单。条理和叙述方式有待加强，终于又写了一篇blog，欢迎交流反馈~~</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hive compile and apply patch]]></title>
    <link href="http://code6.github.com/blog/2012/09/19/hive-compile-and-apply-patch/"/>
    <updated>2012-09-19T13:38:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/09/19/hive-compile-and-apply-patch</id>
    <content type="html"><![CDATA[<p class="date">2012-09-20</p>
<p>回归来的第一篇，另外还有好几篇躺在 <code>published:false</code> 中，还没搞好 :-(</p>
<p>这个礼拜最大的收获是编译啥啥啥还是蛮简单的，又没叫你去改代码。有些东西动手尝试一下，往往会发现没有多难，不能停留在口上上说说而已。看到 <a href="http://blog.liancheng.info/wq-2008-1/">一段相关但不是很切题的话</a> :</p>
<blockquote>
<p>不可忽视的一点是：在技术性团体里，做永远比说要来的有效。在想法成熟之前就贸然游说，往往会招致相反的效果。大家都是工程师，不会贸然接纳陌生事物。如果自己都还没有想清楚就开始大肆游说，往往会被大家提出的实际的工程问题驳斥地体无完肤。当你哑口无言之时，大家也已经对你的方案产生了难以磨灭的 “不靠谱”的第一印象，这时要再想咸鱼翻身，可就没那么容易了。</p>
</blockquote>
<blockquote>
<p>相对的，首先自行查阅文档资料并进行试验，制作demo，通过试验发现和解决实际出现的问题。在想法基本成型时，和个别观念开放的同仁进行探讨，这时往往可以发现大量之前自己没有考虑到的问题，再转而细化方案。这个过程反复迭代几次之后，方案和demo逐渐成熟，同时也潜移默化地达到了传教的目的。等到方案完全成熟之后，再拿出实际可工作的demo开始游说，这时自然就成竹在胸了。</p>
</blockquote>
<p>进入正题，这里主要是参考几篇文章，说说编译hive和打补丁, 或者说贴贴链接= =</p>
<h3>hive 代码编译</h3>
<p><a href="http://railsbuilder.blogspot.com/2010/06/installing-hive-on-linux.html">install hive on linux</a>  <br />
<a href="http://blog.csdn.net/scutshuxue/article/details/5915689">使用ant编译hive</a>  <br />
<a href="http://blog.csdn.net/cfy_yinwenhao/article/details/6977882">hive打补丁编译hive</a></p>
<p>这里我在ubuntu上操作的, 编译hive需要依赖 <span class="caps">JAVA</span>, <span class="caps">ANT</span> (这里不依赖hadoop原因是ant会自动去下载hadoop)。 <br />
安装好后export <code>JAVA_HOME</code> , <code>ANT_HOME</code> 变量 (我直接加入.bashrc当中了)。<br />
接下来去官网下载hive源码包。这里我使用的是 <code>hive.0.9.0</code> 。 解压之后进入src目录，需要修改一些配置:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>build&#46;properties </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hadoop.version=1.0.1
</span><span class='line'>
</span><span class='line'>主要是facebook被墙了，镜像地址可参考 http://www.apache.org/dyn/closer.cgi/hadoop/core/
</span><span class='line'>hadoop.mirror1=http://mirror.bjtu.edu.cn/apache  
</span><span class='line'>hadoop.mirror2=http://mirror.bjtu.edu.cn/apache
</span><span class='line'>
</span><span class='line'>以下的修改主要是看到镜像中的hadoop版本已经没有默认的版本号了，估计是不支持了?故改成包含的版本号。
</span><span class='line'>hadoop-0.20.version=0.20.2
</span><span class='line'>hadoop-0.20S.version=1.0.1 (S的版本不知有没有啥区别)</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>接下来执行 <code>ant package</code> 即开始编译了, 结果默认会放在 <code>build/dist</code> 目录中，使用 <code>-Dtarget.dir=xxx</code> 可以更新目标位置。</p>
<p>如果BUILD FAIL的话，一般参考提示可以看出是哪里出了问题(遇到比较多还是被墙的问题= =)。</p>
<h3>hive 单元测试</h3>
<p><a href="http://www.oratea.net/?p=632">hive中的单元测试</a><br />
<a href="http://blog.csdn.net/bupt041137/article/details/6553770">hive中的test case</a><br />
<a href="http://blog.csdn.net/bupt041137/article/details/6553760">QtestUtil.java</a><br />
<a href="http://blog.csdn.net/bupt041137/article/details/6553760">hive unit test</a></p>
<p>hive 中的 <a href="https://cwiki.apache.org/Hive/howtocontribute.html#HowToContribute-UnitTests">单元测试</a> 还是蛮有趣的，既有传统的单元测试代码，又可以批量执行查询脚本判断结果是否一致:</p>
<blockquote>
<p>在hive中会有大量的.q的文件即执行测试的query文件，.q.out是测试的结果文件。 进行新测试后产生的结果和标准的q.out一致则表示测试成功。<br />
具体来说，src/ql/src/test/queries下面是测试用例，clientpositive是运行成功的用例，clientnegative是运行失败，返回非0的用例。 src/ql/src/test/results 下面是测试用例对应的输出结果。 如src/ql/src/test/queries/case_sensitivity.q对应的输出结果是src/ql/src/test/results/case_sensitivity.q.out 。</p>
</blockquote>
<p>使用 <code>ant test</code> 运行单元测试，不过此命令要跑好多测试， <a href="https://builds.apache.org/job/Hive-trunk-h0.21/1671/testReport/org.apache.hadoop.hive.cli/TestCliDriver/">光TestCliDriver一项就要跑好几个小时</a> , 我们可以</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>ant test </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>运行所有的正面的测试
</span><span class='line'>ant test -Dtestcase=TestCliDriver
</span><span class='line'> 
</span><span class='line'>运行特定的测试，以groupby为例子
</span><span class='line'>ant test -Dtestcase=TestCliDriver -Dqfile=groupby1.q</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>使用 <code>-Doverwrite=true</code> 可以覆盖结果文件，后面有新的更新想测试表现是否一致的时候就可以使用了, 通常在我们增加新的udf的时候可以这么来生成测试数据。</p>
<h3>hive代码打补丁</h3>
<p>下载了 <code>hive 0.9.0</code> 稳定版，不过发布之后还是有若干bug，这时搜索一下 <code>hive jira</code> 一般能看到相应ticket，比如 <a href="https://issues.apache.org/jira/browse/HIVE-2942">这个substr遇到UTF8的问题</a> 。一般打的补丁会走一个 <code>publish-review-apply</code> 的 <a href="http://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;cad=rja&amp;ved=0CEIQFjAD&amp;url=http%3A%2F%2Fwww.cs.pdx.edu%2F~bart%2Fpapers%2Fpicmet-patch.pdf&amp;ei=g0VbUK6LDITqmAW2tICQCQ&amp;usg=AFQjCNEoh5FKA_8KNBa5-Pr-gMaQPHS9GA&amp;sig2=ISd1WAautuWBKKfc_Vv3lg">过程</a> ，准确解决问题的补丁会被加入版本库中，而临时补丁一般不会采用。作为用户，有时难免得打一些这样的补丁。打补丁也很方便，下载社区提供的补丁之后，使用 <code>patch</code> 命令即可以应用到源码中, 后续在进行编译测试即可。</p>
<p>另外我们有时会有需求将 <a href="http://my.oschina.net/wangjiankui/blog/64230">自己使用的 udf 编译到hive当中以方便使用</a> ，这其实也可以看成打补丁的行为。</p>
<p>打补丁多了，管理是后面会遇到的问题。 就个人而言，可以自己载个官方的git仓库，然后开分支来维护自己的变更。如果要多人协作的话，可以创建一个新的git仓库，然后添加两个远端, 其中一个是官方的git仓库，另外一个可以是大家从某个分支开始维护的版本。纯属yy，实际操作起来也未必省心。 这里看起来使用 <a href="https://github.com/blog/674-introducing-organizations">github organization</a> 是蛮适合的。</p>
<p>当然，可以预见的是，大部分时间我们都不会打补丁，可能只会在新增一些UDF= =, 于是似乎完全没有必要这么干, 大概 <a href="https://github.com/nexr/hive-udf">类似这样就可以了</a> , 看起来一般将用到的udf打包，然后要用的时候加一句声明即可。</p>
<p>不过我还是蛋疼去搞了一个 <a href="https://github.com/MTDATA/hive">organization</a> , fork一下官方代码。 我在本地git加入 <code>apache/hive</code> 作为另一个远端, 称为 <code>mirror</code> 。由于我们目前使用的是 0.9, 故我考虑的是在 <code>origin/branch-0.9</code> 下做开发，并将 <code>mirror/branch-0.9</code> 定期 merge 回 <code>branch-0.9</code> 。至于 <code>trunk</code> 则不动。</p>
<p>这样一来我就开始捣鼓了，首先还是改 <code>build.properties</code> , 我将这些也一并提交到分支里面了。 然后我开始将 udf 编译进去，这次遇到一个比较坑爹的问题就是 <strong>编译一直成功，但是执行单元测试一直找不到新的UDF</strong> 。 捣鼓了很久无果后找小美支援，小美在分析一阵之指出测试的时候没有引用到编译的 <code>FunctionRegistry.class</code> , 估计使用到别的旧的文件了。又过了一段时间之后我确实发现有个地方 <code>~/.ivy2/</code> 下面有一些cache, 简单google之后又发现 <code>hive jira</code> 上已经有一个 <a href="https://issues.apache.org/jira/browse/HIVE-3092">tck</a> , 看了大概是由 <a href="https://issues.apache.org/jira/browse/HIVE-2646"><span class="caps">HIVE</span>-2646</a> 引入的, 导致测试的时候会从ivy cache来加载hive相关的类而不是 <code>build/dist/lib</code> 。这个改动恰恰不在 0.9.0发布版但是 commit到 <code>branch-0.9</code> 中了, 所以我从 <code>branch-0.9</code> 的代码开始编译就中招了。这个patch有加入trunk中，故 <code>cherry-pick</code> 一下即可(本来我打算直接打patch的)。当然这里我不清楚为啥这个补丁不加入 0.9 分支，估计不算大问题? 没有运行bug？从版本库编译就是比较坑爹= =</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[learning Algo Part I at coursera.org]]></title>
    <link href="http://code6.github.com/blog/2012/09/19/learning-algo-part-i-at-coursera-dot-org/"/>
    <updated>2012-09-19T01:55:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/09/19/learning-algo-part-i-at-coursera-dot-org</id>
    <content type="html"><![CDATA[<p>用来记录我在 coursera.org 上学习  Algo Part I的记录，写完之后发布。</p>
<p>看起来要来不及了。。。要不然就看PPT恶补吧，dealline(9月30号)快到了。</p>
<p>2012.12.16<br />
以上已经完全来不及= = 我的第一门coursera课就这样悲剧了。<br />
另外后续我跟小美同学一起开始学 compiler 这门课，还是没有分出足够的时间来做相应的学习，不过小美同学就很有效率地完成了大部分作业。<br />
近期我的 <a href="https://www.coursera.org/course/algo2">第三门课</a> 已经开课两个星期了，我感觉必须搞定这种被时间追赶着的状态。<br />
之前一直困扰我的是网络太差，看视频太麻烦，于是google 一个能下载视频的脚本，果然 <a href="https://github.com/jplehmann/coursera">很容易在github上找到了</a> 。<br />
代码写的还蛮简单漂亮的，后续下载视频只需要一句话:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>coursera video download </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/Users/code6/git/coursera/coursera-dl -n --path  "/Users/code6/Downloads/coursera/videos/algo2/"  -w /usr/local/bin/wget algo2-2012-001</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>如果一个东西很难获得，势必增加做某件事情的阻力，但如果太容易获得，也是如此，在下载视频这件事来看也是如此。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[unit test for etl script]]></title>
    <link href="http://code6.github.com/blog/2012/09/14/unit-test-for-etl-script/"/>
    <updated>2012-09-14T07:12:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/09/14/unit-test-for-etl-script</id>
    <content type="html"><![CDATA[]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[back for blogging more]]></title>
    <link href="http://code6.github.com/blog/2012/09/13/back-for-blogging-more/"/>
    <updated>2012-09-13T04:31:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/09/13/back-for-blogging-more</id>
    <content type="html"><![CDATA[<p class="date">2012-09-13</p>
<p>感到很失败，未能完成之前所说的一周发表一篇blog的计划。<br />
但我还是有很多想说的，感觉如果在工作中不能记录下只言片语的话，那到头来就没有什么留下了了，所谓经验其实远不如总结沉淀来得安稳。<br />
但我是不是没有干活呢，只能说是懒惰，不想多费些时间心力来记录生活，学习。<br />
那今天是什么一个情况呢，组里面吃饭的时候在讨论一些问题，聊到了执行力，能力。想想我在blogging上的动作，实在羞愧。<br />
其实有很多方面可以记录，无论是失败还是成功，我常常想所谓的不成熟其实是最大的阻碍，就像wiki一样，先有了，然后可以慢慢更新的，犯不着要一下子就掌握的非常好。<br />
所以，仅以此blog作为契机，让我再次开始记录生活，记录工作。<br />
blog是另外一种认识自己的方式，可以更深刻，更有味道。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[pyhive - hive thrift 查询简单封装]]></title>
    <link href="http://code6.github.com/blog/2012/06/04/pyhive-simple-python-thrift-lib-for-executing-hive-queries/"/>
    <updated>2012-06-04T20:15:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/06/04/pyhive-simple-python-thrift-lib-for-executing-hive-queries</id>
    <content type="html"><![CDATA[<p class="date">2012-09-13</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[6月第一周比赛小计]]></title>
    <link href="http://code6.github.com/blog/2012/06/03/programming-contest-fun-in-the-first-weekend-of-june/"/>
    <updated>2012-06-03T09:41:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/06/03/programming-contest-fun-in-the-first-weekend-of-june</id>
    <content type="html"><![CDATA[<p class="date">2012-06-04</p>
<p>6月第一个周末比赛好多啊，做了其中的4个，很爽:</p>
<table>
	<tr style="background:#ddd;">
		<td style="width:200px;">比赛 </td>
		<td style="width:200px;">开始时间 </td>
	</tr>
	<tr>
		<td> Astar 2012 R1a  </td>
		<td> 2012.6.2 10:00 </td>
	</tr>
	<tr>
		<td> <a href="http://ipsc.ksp.sk/contests/ipsc2012/results/">ipsc 2012</a>  </td>
		<td> 2012.6.2 18:0 0</td>
	</tr>
	<tr>
		<td> <span class="caps">TCO</span> 2012 R2c  </td>
		<td> 2012.6.3 00:00 </td>
	</tr>
	<tr>
		<td> Astar 2012 R1b  </td>
		<td>2012.6.3 10:00</td>
	</tr>
</table>
<p></p>
<p>结果不是很重要，关键是又稍微思考了下, 但这样没有规律的思考是无法提高的，倒是也得想办法弄一个周期性较强的训练时间, 挨个稍微说一下吧。</p>
<ul>
	<li><strong>Astar 2012 R1a</strong></li>
</ul>
<table>
	<tr style="background:#ddd;">
		<td style="width:100px;">题目ID </td>
		<td style="width:200px;">标题 </td>
	</tr>
	<tr>
		<td>A     </td>
		<td>  度度熊就是要第一个出场</td>
	</tr>
	<tr>
		<td>B     </td>
		<td>  小小度刷礼品</td>
	</tr>
	<tr>
		<td>C     </td>
		<td>  集合的交与并</td>
	</tr>
	<tr>
		<td>D     </td>
		<td>  轮子上的度度熊</td>
	</tr>
</table>
<p></p>
<p>这场做了B和D吧, B就是很土的算1到N里面有多少个以x结尾的数, D的话我暴力了一下，大数据会超时，不过来不及想优化了, 感觉没有优化写起来就像很无聊的DP。 另外A其实是可做的，bfs一下应该就可以了, 跟印象中某ZOJ月赛一题有像，也跟今年的WF的镜面反射的题目有点相似(题型)。 感觉运气好可以晋级吧，毕竟只做了1题多一点点而已。</p>
<ul>
	<li><strong>ipsc 2012</strong><br />
与毛哥一起搞了今年的ipsc, 用的是我们当年组队的名字 <code>ACOrz</code> , 可惜daxia没来一起做。稍微迟到了半小时，毛哥已经把A过了，然后看了C, F, I了。C我尝试了两三次，无果，后面先放弃了。放弃C之后就很顺了，跟毛哥一起砍了一些大众题目。依次是
	<ul>
		<li>G<br />
算有向图最大长度的链。由于图挺特殊的，只有一个出度，故也挺好算。</li>
		<li>I<br />
<a href="http://www.md5decrypt.org/">md5 decrypt</a> 挺好用的，直接将大小数据都过了= =国内的网站就不行，还要收费- -</li>
		<li>F<br />
毛哥暴力了小数据，然后我们在只有两个硬币的情况下做简单演算, 得到 <code>p1*(1-p2)+p2*(1-p1)=1/2</code>  这个式子，直接解出 <code>p1 = 1/2 or p2 = 1/2</code>  , 于是也很容易了。</li>
		<li>C1<br />
C1 后面我又试了下记忆化搜索，于是就过了= =, 一开始dp比较随意了，改成记忆化暴力所有可能于是过了。猜测大数据也是类似搞法，不过状态可能稍微多了，未作深究。</li>
		<li>B<br />
B毛哥猜得很欢乐， B1还好，B2我们真是非常惊险，猜到第30次才得到答案(最多猜测30次)，毛哥还用啥迭代法来逼近来着。<br />
<img src="http://code6.github.com/images/ipsc_2012-2.png"><br />
最终ipsc排名一百多名，算是本周最欢乐的比赛了，当然还有很多没有切出来, 回头可以再看看。<br />
<img src="http://code6.github.com/images/ipsc_2012-1.png"></li>
	</ul></li>
</ul>
<ul>
	<li><span class="caps">TCO</span> 2012 R2c<br />
ipsc 做到了晚上11点结束，12点就是 <code>TCO R2c</code>了，能不能拿衣服就看这场了。悲剧的是比赛前20分钟家里断网了，折腾了好些,搞好的时候已经12点20分了，顾不上就奔去了。300分是一个有点代码量的枚举，写到了144分。。500打开只有半小时了，看了下，这不就是土土的树状数组吗！马上搞啊搞，在最后10分钟的时候样例一直过不了，还有一个即simple的样例，没来得及看明白 比赛结束了。后面再看了下，发现题目看错了= = 顺序有点小变化，当然做法还是树状数组。感觉构造还是挺巧妙的，多增加了啥，该扣除啥。另外本次的900pt貌似也可做，没来得及看，某些人直接搞900晋级了，真给力。</li>
</ul>
<ul>
	<li>Astar 2012 R1b<br />
由于2号搞到比较晚，起床的时候已经是10:30了，外加还得洗碗= = 题目现在看不到了，仍然是4道题。最终做了B, C。B是二分加并查集，挺简单的。C 简单yy了一个贪心，感觉想简单了。A是算n个数中选若干数异或值的最大和次大，没想明白，  <a href="http://hi.baidu.com/pojoflcc/blog/item/c85dccdbb967c0c1b7fd4805.html">别人说是&#8217;搞基&#8217;</a> 。 D没有想法。 这场要晋级的话也比较悬，重在参与~</li>
</ul>
<p>总之，整个周末还是挺紧凑以及有趣的(还出去骑了两次车)，每次比赛后都留下一些未解之谜，现在不能像以往一一攻克并提高战斗力了，不过真想把不会的继续搞懂！</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[deal with special characters in hive query result]]></title>
    <link href="http://code6.github.com/blog/2012/05/21/deal-with-special-characters-in-hive-query-result/"/>
    <updated>2012-05-21T01:21:00+02:00</updated>
    <id>http://code6.github.com/blog/2012/05/21/deal-with-special-characters-in-hive-query-result</id>
    <content type="html"><![CDATA[<p class="date">2012-06-02</p>
<p>知识，想法是需要整理的， 不然容易遗忘, 又过了好久没有更新, 怨念= -<br />
这段时间搞了一点hive之类的东西，遇到一些问题，后续也许还会整理一点出来。<br />
最近遇到的关于hive的问题是:</p>
<blockquote>
<p>将hive查询结果从临时文件导入mysql的时候, 由于查询结果中有特殊字符(比如反斜杠, 制表符等), 导致数据导入mysql时解析出错。</p>
</blockquote>
<p>这里得先说明一下mysql导入导出的默认行为。 <a href="http://stackoverflow.com/questions/7287658/mysql-escape-backslash">mysql命令行输出默认会做转义</a> 并且在 <a href="http://dev.mysql.com/doc/refman/5.0/en/server-sql-mode.html#sqlmode_no_backslash_escapes">导入的时候默认会将反斜杠转义</a> , 我们一般不会感觉到这一步。当相同问题发生在hive的查询结果时,有些时候字段末尾或行末尾的 <code>\</code> 会将间隔符 <code>\t</code> 或换行符 <code>\n</code> 转义, 导致导入出错。 如果关闭mysql导入时默认转义的话, 那么字段中包含的间隔符 <code>\t</code> 会导致列数变多，同样出现问题。</p>
<p>十分讨厌hive查询结果中的特殊字符, 究其原因主要是 <a href="https://issues.apache.org/jira/browse/HIVE-692">hive查询结果目前无法对特殊字符进行转义</a> , 另外比较头疼的是 <code>hive cli</code> 或者 <code>hiveserver</code> 的查询结果中, 默认的字段分隔符都是 <code>\t</code> 且不方便变更。 在解析日志的过程中, 字段中难免包括 <code>\t</code>,  <code>\</code> 这类特殊字符。此问题还得仔细对待, 在网上搜了下，大概有几种方法, 未找着较优雅的方案。</p>
<h3>绕过转义问题</h3>
<p>一种做法是我们绕过此问题。如果我们不对查询结果进行转义，那么我们就只能让mysql不对导入数据进行转义了( <code>no_backslash_escapes</code> ), 这里需要我们对查询结果给定一个特殊的分隔符，比如 <code>0x01</code> 。</p>
<ul>
	<li><strong><span class="caps">CTAS</span></strong><br />
具体内容即</li>
</ul>
<blockquote>
<p>When you are doing output to the console \T is your only option. The<br />
best way to handle this is create another table with the delimiters<br />
you wish and then select into that table. You can do this with <span class="caps">CTAS</span>.</p>
</blockquote>
<p>比如</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>CTAS </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>create table xzy 
</span><span class='line'>row format delimited
</span><span class='line'>fields terminated by '\001'
</span><span class='line'>as select age, dt  from ibtest limit 1;</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>这里可以指定任意的分隔符，但这边文件在 <code>/user/hive/warehouse/xzy</code> 中，我们还得将其合并输出到临时文件中。</p>
<ul>
	<li><span class="caps">INSERT</span> <span class="caps">OVERWRITE</span> <span class="caps">LOCAL</span> <span class="caps">DIRECTORY</span></li>
</ul>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>local directory </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>INSERT OVERWRITE LOCAL DIRECTORY '/mydir'
</span><span class='line'>SELECT XXX</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>直接写到外部文件夹, 此时分隔符为 <code>0x01</code> 。</p>
<ul>
	<li><strong>concat_ws</strong><br />
这个算是一个比较取巧的方法吧，xyc介绍的:<br />
将查询结果先转成string, 然后 <strong>concat</strong> 起来，并指定分隔符。这样由于最终只有一列，所以不会 加上系统默认的分隔符了。</li>
</ul>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>concat_ws </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>select concat_ws('\001', cast(userid as string), cast(cityid as string), regdate) from hiveuser limit 10;</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<h3>勉强进行转义</h3>
<p>另外一种做法是勉强在hql中进行转义, 比如将 <code>\</code> 替换成 <code>\\</code> , 将制表符替换成 <code>\</code> 和 <code>t</code> :</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>regexp_replace </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>regexp_replace(regexp_replace(column, '\\\\', '\\\\\\\\'), '\t', '\\\\t')</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>这里得在可能出现特殊字符的地方做上述修改, 为防止写得繁琐，可以考虑封成 <code>udf</code> 。</p>
<h3>总结</h3>
<p>总而言之，目前并没想到较好的处理方法。反过来想，类似制表符的特殊字符在日志中是否有意义，如果没有的话，可否去掉?  这样一来就愉快多了，但是 <strong>破坏原始日志</strong> ，感觉也不是很好。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to build a dynamic SQL in an elegant way]]></title>
    <link href="http://code6.github.com/blog/2012/03/24/how-to-build-a-dynamic-sql-in-an-elegant-way/"/>
    <updated>2012-03-24T11:27:00+01:00</updated>
    <id>http://code6.github.com/blog/2012/03/24/how-to-build-a-dynamic-sql-in-an-elegant-way</id>
    <content type="html"><![CDATA[<p class="date">2012-04-04</p>
<p>换上octopress, 写blog还是不勤快, 目前装在虚拟机当中，怎么勤快:(。</p>
<p>不岔开话题，这次讨论的是如何 <strong>动态地生成一条查询SQL</strong> 。起因是一个统计报表要新增加一些筛选条件， 而这些筛选条件并非简单加一个where条件，有时还要涉及到联表(join)以及聚合条件的改变。原先我的做法是 设几个变量，诸如where, groupby, joins等，然后再将这几个变量合起来，这之中得考虑逗号，是否需要插入&#8217;and&#8217;等， 简单来说还行，但如果多个地方都需要用到，那么稍微麻烦了，而且代码重复较多, 所以我想找找有没有动态生成查询SQL的更方便的方法。</p>
<p>看到 <a href="http://patrickallaert.blogspot.com/2007/09/building-dynamic-sql-queries-elegant.html">一篇blog</a> , 大概讲的就是平常的一些小技巧吧, 比如使用implode来拼where条件。</p>
<p>后来在stackoverflow看到 <a href="http://stackoverflow.com/questions/2258438/how-do-i-build-a-dynamic-sql-query">一个帖子</a> , 这个问题跟我面对的问题基本一致，帖子的第一个解答即是我最终采取的方案。即是写一些函数来记录主要的内容(select内容，join表与条件, where条件, groupby条件等), 然后按确定的方式来拼出最终的查询语句。</p>
<p>后面看到一个 <a href="http://openhms.sourceforge.net/sqlbuilder/example.html">squlbuilder</a> ，看上去有点重，有很多功能目前都还不需要用到。</p>
<p>最后看到github上的一个 <a href="https://github.com/c9s/SQLBuilder">SQLBuilder</a> ，感觉实现得还不错，当然也有很多我不太需求的功能，故在其基础上删减了一下，快速实现了，放到 <a href="https://github.com/code6/query-builder">github</a> 上了。</p>
<p>一个简单的demo:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>demo 1 </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$sqlbuilder = new QueryBuilder();
</span><span class='line'> $sqlbuilder->table('fact.`order`', 'f')
</span><span class='line'>          ->select(array(
</span><span class='line'>                'city',
</span><span class='line'>               'quantity' => 'sum(quantity)',
</span><span class='line'>               'averageprice' => 'ifnull(sum(revenue) / sum(quantity), 0)'))
</span><span class='line'>          ->join('dim.date', 'd', '', 'f.date = d.date')
</span><span class='line'>          ->where('d.date between ? and ?', 'ss', array($begin_date, $end_date))
</span><span class='line'>          ->groupby('d.month_num_overall')
</span><span class='line'>          ->orderby('d.month_num_overall desc')
</span><span class='line'>          ->limit(3)
</span><span class='line'>          ->offset(3);
</span><span class='line'>
</span><span class='line'>echo $sqlbuilder->build();</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>输出结果格式化如下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>demo 1 output </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT city,
</span><span class='line'>       sum(quantity) AS quantity,
</span><span class='line'>       ifnull(sum(revenue) / sum(quantity), 0) AS averageprice
</span><span class='line'>FROM fact.`order` f
</span><span class='line'>JOIN dim.date d ON f.date = d.date
</span><span class='line'>WHERE d.date BETWEEN ? AND ?
</span><span class='line'>GROUP BY d.month_num_overall
</span><span class='line'>ORDER BY d.month_num_overall DESC,d.month_num_overall ASC 
</span><span class='line'>LIMIT 3, 3</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>其中 <code>getBindParams</code> 函数返回一个数组, 包含绑定的变量的类型以及具体的变量, 比如 <code>array('ii', 1, 2)</code> , 而 <code>getReturnParams</code> 函数则返回查询结果列名数组。</p>
<p>目前还简单增加了 <strong>子查询</strong> 的支持。</p>
<p>一个查询 <a href="http://en.wikipedia.org/wiki/Gini_coefficient">gini系数</a> 的demo如下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>gini demo </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$sub1 = new QueryBuilder();
</span><span class='line'>$sub1->table('fact.`order`', 'f')
</span><span class='line'>  ->where('d.date between ? and ?', 'ss', array($begin_date, $end_date))
</span><span class='line'>  ->where ('coupontype != 4')
</span><span class='line'>  ->orderby('focus', 'f.revenue');
</span><span class='line'>
</span><span class='line'>$sub0 = new QueryBuilder();
</span><span class='line'>$sub0->table(" (select @cs := 0) ", 'cs_idx')
</span><span class='line'>  ->join(" (select @focus:='') ", "s_idx")
</span><span class='line'>  ->join($sub1, 'raw')
</span><span class='line'>  ->select(array('accumulate_revenue' => '@cs := CASE WHEN @focus != raw.focus THEN raw.revenue ELSE @cs + raw.revenue END',
</span><span class='line'>                'focus' => '@focus := raw.focus'));
</span><span class='line'>
</span><span class='line'>$gini  = new QueryBuilder();
</span><span class='line'>$gini->table($sub0, 'base')
</span><span class='line'>  ->select(array(
</span><span class='line'>        'focus',
</span><span class='line'>       'g' => 'truncate(1 - 1.0 / count(*) * (2 * sum(base.accumulate_revenue) / max(base.accumulate_revenue) -1), 2)'))
</span><span class='line'>  ->groupby('base.focus');
</span><span class='line'>
</span><span class='line'>echo $gini->build();</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>输出如下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>gini demo output </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT focus,
</span><span class='line'>       truncate(1 - 1.0 / count(*) * (2 * sum(base.accumulate_revenue) / max(base.accumulate_revenue) -1), 2) AS g
</span><span class='line'>FROM
</span><span class='line'>  (SELECT @cs := CASE
</span><span class='line'>                     WHEN @focus != raw.focus THEN raw.revenue
</span><span class='line'>                     ELSE @cs + raw.revenue
</span><span class='line'>                 END AS accumulate_revenue, @focus := raw. focus AS focus
</span><span class='line'>   FROM
</span><span class='line'>     (SELECT @cs := 0) cs_idx
</span><span class='line'>   JOIN
</span><span class='line'>     (SELECT @focus:='') s_idx
</span><span class='line'>   JOIN
</span><span class='line'>     ( SELECT f.FOCUS AS focus,
</span><span class='line'>          f.revenue
</span><span class='line'>      FROM fact.`order` f
</span><span class='line'>      WHERE d.date be tween ?
</span><span class='line'>        AND ?
</span><span class='line'>        AND coupontype != 4
</span><span class='line'>      ORDER BY focus,
</span><span class='line'>               f.revenue) raw) base
</span><span class='line'>GROUP BY base.focus</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>代码测试方面, 后面发现参考代码是使用 <a href="http://www.phpunit.de/manual/current/en/installation.html">phpunit</a> 来进行单元测试的，简单地使用一下，还是挺好用的:)</p>
<p>目前还算能满足需求，当然对于预处理语句的变量处理还可以改进，收集需求再改进吧。</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Octopress Setup]]></title>
    <link href="http://code6.github.com/blog/2012/03/09/octopress-setup/"/>
    <updated>2012-03-09T08:10:00+01:00</updated>
    <id>http://code6.github.com/blog/2012/03/09/octopress-setup</id>
    <content type="html"><![CDATA[<p class="date">2012-03-09</p>
<p><img src="http://code6.github.com/images/octopress_logo.png"></p>
<p>最早是在lzyy的blog看到 <a href="http://blog.leezhong.com/tech/2010/08/25/make-github-as-blog-engine.html">使用github作为博客引擎</a>, 后面在github上看到了 <a href="https://github.com/lzyy/lzyy.github.com/blob/master/_posts/2010-08-25-make-github-as-blog-engine.textile">他的博客的源代码</a> , 顿时感觉很不错, 这样写blog大概有几个优点:</p>
<ul>
	<li><strong>markdown</strong><br />
可以使用惯用的markdown来写文章(比如我觉得 <a href="http://redcloth.org/textile">textile</a> 跟 <a href="http://www.atlassian.com/software/confluence/overview">confluence</a> 的编辑语法很像)</li>
	<li><strong>git &amp;&amp; githhub</strong><br />
使用git进行版本控制, 放在github上保存, 使用 <a href="http://pages.github.com/">github pages</a> 发布, 空间再不是写blog的障碍了:)</li>
</ul>
<p>经过约一周的围观与尝试= =, 差不多搞到可用了，剩下了就是加page, 搞插件，熟悉语法了。捣鼓过程无比心酸, 鉴于一个windows用户, 又不愿在windows上搞, 碰巧vmplayer中仅有一台别人配的centos, 于是开始捣鼓了。octopress 需要ruby, python(其中用到 <a href="https://github.com/halostatue/rubypython">rubypython</a> 似乎有依赖), git, ssl等一系列乱七八糟的东西, 按官方的说明去安装倒也无碍, 不过由于之前随意安装了一些低版本的东西, 往往会导致后面发现跑不起来, 于是也多了很多弯路, 总的来说, <strong>顺风顺水的话, 安装还是很容易的</strong>。</p>
<h3><strong>Octopress Setup</strong></h3>
<p>安装过程可以参考官方文档(参见附录), 这里结合我的环境(centos 5.7)复述一下, 后面再说说我遇到的囧问题。</p>

	<ul>
		<li><strong>git &amp;&amp; github</strong><br />
首先要有git, 为了在github上保存且发布, 要申请一个github账号并上传ssh key以支持push, 见 <a href="http://help.github.com/">github帮助</a> 。</li>
	</ul>
	<ul>
		<li><strong>创建ruby环境</strong><br />
octopress 需要 ruby 1.9.2, 用 <a href="https://github.com/wayneeseguin/rvm">rvm</a> 可以方便安装, 先安装rvm</li>
	</ul><p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>install rvm  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>bash -s stable &lt; &lt;<span class="o">(</span>curl -s https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>为了更方便使用rvm, 我们将其加入bash_profile中</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>add rvm to bash_profile  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">echo</span> <span class="s1">&#39;[[ -s &quot;$HOME/.rvm/scripts/rvm&quot; ]] &amp;&amp; . &quot;$HOME/.rvm/scripts/rvm&quot; # Load RVM function&#39;</span> &gt;&gt; ~/.bash_profile
</span><span class='line'><span class="nb">source</span> ~/.bash_profile
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>安装ruby 1.9.2 获取最新的 <a href="http://rubygems.org/">rubygems</a> , 并安装 <a href="http://gembundler.com/">bundler</a></p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>install ruby  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>rvm install 1.9.2 <span class="o">&amp;&amp;</span> rvm use 1.9.2
</span><span class='line'>rvm rubygems latest
</span><span class='line'>ruby --version  <span class="c"># Should report Ruby 1.9.2</span>
</span><span class='line'>gem install bundler
</span></code></pre></td></tr></table></div></figure></div></notextile></p>

	<ul>
		<li><strong>下载并安装octopress</strong></li>
	</ul><p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>install octopress  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git clone git://github.com/imathis/octopress.git octopress
</span><span class='line'><span class="nb">cd </span>octopress    <span class="c"># If you use RVM, You&#39;ll be asked if you trust the .rvmrc file (say yes).</span>
</span><span class='line'>bundle install  <span class="c">#install dependencies</span>
</span><span class='line'>rake install    <span class="c"># Install the default Octopress theme.</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>上文中用到一个 <a href="http://rake.rubyforge.org/">rake</a> , 可以认为就是一种预先编好的 <strong>任务脚本</strong> , 观察文件夹中有一个 <code>Rakefile</code> 打开看看就大概猜了下。</p>
<p>到这一步基本在本机上已经安装好octopress了, 我们可以把它发布到Github上(当然你还可以部署到 <a href="http://octopress.org/docs/deploying/">其他地方</a> )。首先你得建一个以用户名命名的类似 <code>username.github.com</code> 的Repository。比如我的就是 <code>code6.github.com</code>, 然后设定Github Pages:</p>
<div>
<pre>
<code class='bash'>rake setup_github_pages</code>
</pre>
</div>
<p>之后会要求 <code>read/write url for repository</code> 。 <br />
将 <strong>git@github.com:yourname/yourname.github.com.git</strong> 替换成自己的即可。</p>

	<ul>
		<li><strong>建立和发布</strong></li>
	</ul><p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>deploy  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>rake generate
</span><span class='line'>rake deploy
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>很简单吧, 两条命令就搞定了~, 接下来就可以浏览 <code>http://username.github.com</code><br />
这里我们是将生成的站点的静态文件发布到了 <code>username.github.com</code>这个仓库的master分支上, 但这并不包含我们的源文件。 这里我们可以将原始文件提交到source分支上</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>initial commit  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git add .
</span><span class='line'>git commit -m <span class="s1">&#39;initial source commit&#39;</span>
</span><span class='line'>git push origin <span class="nb">source</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>

	<ul>
		<li><strong>目录结构</strong></li>
	</ul><p>到这里我们基本搞差不多了, 可以开展日常工作了，这里可以先熟悉相应的代码结构。<br />
这里主要的目录有 <code>source</code> , <code>public</code> , <code>_deploy</code> , 还有个全局配置文件 <code>_config.yml</code> 。<br />
其中<br />
<code>source</code> 为源文件目录, 我们写的文章就在 <code>source/_posts</code> 中, 当然还包括布局, 页面等好多东西<br />
<code>public</code> 为渲染后的静态blog目录<br />
<code>_deploy</code> 是用来需要部署的文件目录, 大概觉得是 <code>public</code> 的一份拷贝<br />
<code>_config.yml</code> 是全局的配置文件, 语法参考 <a href="http://www.ibm.com/developerworks/cn/xml/x-cn-yamlintro/">这里</a></p>
<p>这里插一个题外话, octopress是基于 <a href="https://github.com/mojombo/jekyll">Jekyll</a> 的, 最开始尝试时下载了jekyll, 由于前端方面的薄弱技能, handler不住, 于是才使用octopress的。最初还看了一个 <a href="https://github.com/plusjade/jekyll-bootstrap">jekyll-bootstrap</a> , 用起来也不麻烦，但猜测没有octopress强大这边的 <code>_config.yml</code> , <code>source</code> 都跟jekyll中的有关, 于是后面如果要捣鼓的话, 可以在那边多看看。 <code>source</code> 目录可以参考jekyll的相关 <a href="https://github.com/mojombo/jekyll/wiki/Usage">wiki</a> 。</p>

	<ul>
		<li><strong>日常任务</strong></li>
	</ul><p><strong>建立新文章</strong><br />
文章必须发表在 <code>source/_posts</code> 下，命名成 <code>YYYY-MM-DD-post-title.markdown</code> 的格式， 我们可以使用octopress的rake 任务来快速创建一篇新文章:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>rake new post  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>rake new_post<span class="o">[</span><span class="s2">&quot;Zombie Ninjas Attack: A survivor&#39;s retrospective&quot;</span><span class="o">]</span>
</span><span class='line'><span class="c"># Creates source/_posts/2011-07-03-zombie-ninjas-attack-a-survivors-retrospective.markdown</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>默认的后缀是 <code>markdown</code> , 可以在 Rakefile中修改。通过此任务创建的文章会补上开头的 <a href="https://github.com/mojombo/jekyll/wiki/yaml-front-matter">元信息</a> 。<br />
接下来我们就可以用自己喜爱的编辑器来编辑了。</p>
<p><strong>建立页面</strong><br />
略</p>
<p><strong>生成与预览</strong><br />
当我们完成一篇文章的创作时，我们可以在本机预览我们的文章。</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>generate and preview  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>rake generate   <span class="c"># Generates posts and pages into the public directory</span>
</span><span class='line'>rake preview    <span class="c"># Watches source/ and sass/ for changes and regenerates, and mounts a webserver at http://localhost:4000</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>其中 <code>rake generate</code> 是将文章和页面生成到 <code>public</code> 目录中，后面我们才能发布我们的改动。<br />
<code>rake preview</code> 会在本地4000端口起一个网站服务器, 我们访问 <code>http://localhost:4000</code> 则可以看到自己的博客。还有一点是它会监听 <code>source</code> 和 <code>sass</code> 的改动，并重新生成文件，也就是说我们无需重启服务器就可以预览最新的文章。</p>
<p><strong>发布</strong><br />
同上文。</p>
<p><strong>更新octopress</strong></p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>upgrade octopress  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git pull octopress master     <span class="c"># Get the latest Octopress</span>
</span><span class='line'>bundle install                <span class="c"># Keep gems updated</span>
</span><span class='line'>rake update_source            <span class="c"># update the template&#39;s source</span>
</span><span class='line'>rake update_style             <span class="c"># update the template&#39;s style</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>更多请参考 <a href="http://octopress.org/docs/blogging/">官方文档</a> 。</p>
<p><strong>textile语法参考</strong><br />
考虑使用textile来写blog, 可以从很多github上的repo中来学习。参考 <a href="https://github.com/mojombo/jekyll/wiki/sites">github上挂的Jekyll的站点</a> , 或者参考 <a href="http://redcloth.org/hobix.com/textile/">相关手册</a> 。 注意文件后缀名不要 <strong>拼错</strong> , 否则无法渲染。 使用过程中感觉textile对于 <strong>空格要求比较严格</strong> , 该 <strong>留空格</strong> 的地方还得留一下, 另外段落之间也最好 <strong>留一个空行</strong> 。 另外发现textile的一些标签不是非常好用, 还得自己做尝试才能得到预期效果。 当然你也可以考虑直接使用 <a href="http://wowubuntu.com/markdown/">markdown</a> 。</p>
<h3><strong>安装补充</strong></h3>
<p>这边主要想说一下我所遇到的问题，当然不是所有人都会遇到，仅限于比较悲剧的人来说。</p>
<p><strong>GemFile</strong><br />
把源改成http://ruby.taobao.org, 据说会比较快, 具体我这边就是讲 <code>gem</code> 和 <code>GemFile</code> 稍微改了下。</p>
<p><strong>ruby blows up with gem dependency</strong><br />
参考 <a href="http://stackoverflow.com/questions/4262616/ruby-1-9-2-blows-up-with-json-gem-dependency">这里</a> , 重装一下ruby并升级一下:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>reinstall ruby  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>rvm uninstall 1.9.2
</span><span class='line'>gem update --system;
</span><span class='line'>gem pristine --all
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p><strong>rubypython 调用到libpython2.&#215;.so失败</strong></p>
<p>由于我先前是用pythonbrew来安装python的，装了python2.7, 本机自带了一个python2.4。 我将pythonbrew关掉, 就ok了，未深究。</p>
<p><strong>ruby环境安装不全</strong><br />
通过 <code>rvm requirements</code> 查看一下需要预先安装什么，然后装好再重装ruby= =</p>
<p><strong>rdiscount fail to generate</strong><br />
据说 <code>rdiscount</code> 会快一些, 这里重装一下就好了。。</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>reinstall rdiscount  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>gem uninstall rdiscount
</span><span class='line'>gem install rdiscount
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p><strong>deploy时拷贝swp/swo文件失败</strong><br />
简单在deploy时忽略swp,swo文件, 在Rakefile中修改:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>modify rakefile  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="no">FileList</span><span class="o">[</span><span class="s2">&quot;</span><span class="si">#{</span><span class="n">args</span><span class="o">.</span><span class="n">source</span><span class="si">}</span><span class="s2">/**/.*&quot;</span><span class="o">].</span><span class="n">exclude</span><span class="p">(</span><span class="s2">&quot;**/.&quot;</span><span class="p">,</span> <span class="s2">&quot;**/..&quot;</span><span class="p">,</span> <span class="s2">&quot;**/.DS_Store&quot;</span><span class="p">,</span> <span class="s2">&quot;**/._*&quot;</span><span class="p">,</span> <span class="s1">&#39;**/.*.swp&#39;</span><span class="p">,</span> <span class="s1">&#39;**/.*.swo&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">file</span><span class="o">|</span>
</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p><strong>异地重新clone一份blog的时候deploy失败</strong><br />
参考 <a href="https://github.com/imathis/octopress/issues/412">这个issue</a> ，看起来重新clone的时候还需要再次执行一边 <code>rake setup_github_pages</code> 才行。</p>
<p><strong>rake preview 报&quot;sorry i cannot find /&quot;</strong><br />
看起来是public目录没有生成完整，可以尝试一下 <code>rake generate</code> 一下再 <code>rake preview</code> 。</p>
<hr />
<h3 style="vertical-align:middle;"><strong>附录</strong></h3>
<p><a href="http://octopress.org/docs/setup/">Octopress Setup</a><br />
<a href="http://lyhdev.com/note:octopress">Octopress: a blogging framework for hackers</a><br />
<a href="http://www.yangzhiping.com/tech/octopress.html">Ruby开源项目介绍(1):octopress&#8212;像黑客一样写博客</a><br />
<a href="http://mrzhang.me/blog/blog-equals-github-plus-octopress.html">Blog = GitHub + Octopress</a><br />
<a href="http://www.yangzhiping.com/tech/github.html">如何高效地使用GitHub</a><br />
<a href="http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html">Blogging Like a Hacker</a></p>]]></content>
  </entry>
  
</feed>
